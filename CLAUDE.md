# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project

**slea-ssem**: AI-driven learning platform for S.LSI employees. Two-round adaptive testing with RAG-based dynamic question generation, LLM auto-scoring, and ranking system.

## Tech Stack

- **Backend**: FastAPI (Python 3.11+)
- **Database**: PostgreSQL + Alembic (migrations)
- **Package Manager**: uv
- **Testing**: pytest
- **Code Quality**: ruff, black, mypy (strict), pylint

## Development

### Quick Start (4 Commands)

```bash
./tools/dev.sh up              # Start dev server (localhost:8000)
./tools/dev.sh down            # Stop dev server (free port)
./tools/dev.sh test            # Run tests
./tools/dev.sh format          # Format + lint code
```

### Common Commands

```bash
./tools/dev.sh cli             # Start interactive CLI
./tools/dev.sh shell           # Enter project shell
./tools/dev.sh help            # Show all commands

tox -e py311                   # Test on Python 3.11
tox -e style                   # Full format/lint pipeline
```

### Server Management with Custom Port

```bash
PORT=8100 ./tools/dev.sh up    # Start on port 8100
PORT=8100 ./tools/dev.sh down  # Stop port 8100 server
```

**Notes**:

- Default port: 8000 (can override with `PORT` env var)
- `down` automatically finds and kills the server on specified port
- `down` works with or without `lsof` command available

### Package Management

**When installing new packages during development**:

```bash
uv add <package-name>          # Add to [project] dependencies
uv add --dev <package-name>    # Add to dev dependencies
```

This automatically updates `pyproject.toml` and `uv.lock`. **Do NOT manually edit pyproject.toml for dependencies** â€” always use `uv add`.

## Testing

### Test Suite Structure

```
tests/
â”œâ”€â”€ backend/          # Backend service & API tests (RECOMMENDED âœ…)
â”œâ”€â”€ agent/            # AI Agent integration tests (optional)
â””â”€â”€ cli/              # CLI command tests (optional)
```

**Total tests**: ~775 tests (backend: ~300, agent: ~200, cli: ~275)

### Quick Test Guide

```bash
# âœ… RECOMMENDED: Run backend tests only (fast, covers most cases)
pytest tests/backend/ -v

# âœ… Run specific backend test file
pytest tests/backend/test_question_gen_service_retake.py -v

# âœ… Run specific test by name
pytest tests/backend/ -k test_retake -v

# â­ï¸ OPTIONAL: Run agent integration tests (slower)
pytest tests/agent/ -v

# â­ï¸ OPTIONAL: Run CLI tests (slower)
pytest tests/cli/ -v

# âŒ AVOID: Full test suite (775 tests, very slow ~10+ mins)
pytest                         # Don't use - too many tests
pytest -k <name>              # Run specific test
pytest -v                      # Verbose output
tox -e py310 py311 py312      # Test multiple versions (developer only)
```

### When to Run Which Tests

| Scenario | Command | Duration |
|----------|---------|----------|
| **After code changes** | `pytest tests/backend/ -v` | ~2-3 min |
| **Before commit** | `pytest tests/backend/ -v` | ~2-3 min |
| **Specific feature testing** | `pytest tests/backend/ -k feature_name` | ~30 sec |
| **Agent integration debugging** | `pytest tests/agent/ -v` | ~3-5 min |
| **CLI command testing** | `pytest tests/cli/ -v` | ~3-5 min |
| **Full validation** (developer only) | `tox -e py311` | ~15+ min |

### Best Practices

- âœ… Always run `pytest tests/backend/ -v` before committing
- âœ… Use `-k` flag to run specific tests: `pytest tests/backend/ -k retake`
- âœ… Use `--tb=short` for cleaner error output: `pytest tests/backend/ -v --tb=short`
- âŒ Don't run full `pytest` without arguments (775 tests = very slow)
- âŒ Don't run agent/cli tests unless debugging those specific features

## Code Quality (Before Commit)

- [ ] `./tools/dev.sh format` passes (ruff, black, mypy, pylint)
- [ ] `./tools/dev.sh test` passes
- [ ] Type hints on all functions (mypy strict mode)
- [ ] Docstrings on public functions
- [ ] Line length â‰¤ 120 chars

## Git Workflow

```bash
./tools/commit.sh              # Interactive commit (Conventional Commits)
./tools/release.sh patch|minor|major  # Release & tag
```

**Commit types**: feat, fix, chore, refactor, test, docs
**Branch format**: `feature/name`, `fix/name`, `hotfix/name`

## Architecture

```text
Frontend â†” Backend (FastAPI) â†” PostgreSQL + LLM/RAG

Key Components:
- User Auth: Azure AD â†’ Session management
- Tests: 2-round adaptive (difficulty adjusts based on score)
- Scoring: MC (exact match) + Short answer (LLM-based)
- Ranking: Global ranking + percentile + category breakdown
```

### Key Files

| Path | Purpose |
|------|---------|
| `src/backend/main.py` | FastAPI app entry (TBD) |
| `src/backend/api/` | Route handlers (TBD) |
| `src/backend/models/` | SQLAlchemy models (TBD) |
| `tests/` | pytest test suite |
| `docs/` | User scenarios, setup guides |
| `alembic/` | Database migrations |

## Data Schema (MVP 1.0)

**Key Entities**:

- `users`: id, ad_id (email), nickname (UNIQUE)
- `users_profile`: user_id (FK), level, career, interests
- `test_sessions`: user_id, round (1-2), status
- `test_questions`: session_id (FK), content, difficulty_level, category
- `test_responses`: session_id, question_id, user_answer, is_correct, score
- `test_results`: user_id, grade, total_score, rank, category_breakdown

## Conventions

**Variable Naming**: snake_case (Python)
**Constants**: UPPER_SNAKE_CASE
**Functions**: verb_noun (e.g., `get_user`, `create_session`)
**Classes**: PascalCase
**Async**: Prefix with `a_` if async function

## Troubleshooting

**Type errors?** Run `tox -e mypy` (strict mode enforced)
**Import errors?** Run `tox -e ruff` then `./tools/dev.sh format`
**DB issues?** Check `alembic/versions/` for migrations, then `./tools/dev.sh up`

### Rich Console Markup Issues

**Problem**: When printing usage strings with square brackets like `[level]`, `[years]`, Rich Console interprets them as markup tags and removes them.

```python
# âŒ Wrong: Will output "Usage: cmd [--option]" (brackets removed)
console.print("Usage: cmd [level] [years] [--option VALUE]")

# âœ… Correct: Use markup=False parameter
console.print("Usage: cmd [level] [years] [--option VALUE]", markup=False)

# âœ… Also correct: Escape with double brackets
console.print("Usage: cmd [[level]] [[years]] [--option VALUE]")
```

**When to use**:

- Use `markup=False` when printing usage/help text with square brackets (cleaner)
- Use `[[...]]` when you need markup enabled elsewhere but want literal brackets

**Cache after changes**: Run `./tools/dev.sh clean` before testing CLI changes, as Python caches compiled modules.

---

## LLM-Based Development Guidelines

### Quick Summary

When working with LLM prompts and LangChain, **always separate content from template logic**. Mixing them causes escaping nightmares when you add JSON examples to prompts.

**Key Pattern**:

```python
# âœ… CORRECT: Use SystemMessage, not from_template()
system_message = SystemMessage(content=prompt_text)  # {} stays as plain text
return ChatPromptTemplate.from_messages([system_message, ...])

# âŒ WRONG: from_template() interprets {} as variables
ChatPromptTemplate.from_template(prompt_text)  # JSON needs escaping!
```

### Two Critical Issues Learned the Hard Way

#### 1. ReAct Format Completeness (LiteLLM Issue)

- **Problem**: LLM sometimes skips Action Input or Observation fields
- **Root Cause**: High temperature (0.7) + vague prompt instructions
- **Solution**: Use temperature 0.3 + explicit format requirements
- **Reference**: `docs/postmortem-litellm-no-tool-results.md`

#### 2. JSON Escaping in Prompts (Template Logic Issue)

- **Problem**: `{"user_id": "..."}` in prompt â†’ interpreted as template variable
- **Root Cause**: Mixing content and logic; using `from_template()`
- **Solution**: SOLID-based refactoring (Builder + Factory patterns)
- **Reference**: `docs/postmortem-prompt-escaping-solid-refactoring.md`

### SOLID-Based Solution (Condensed)

**File Structure**:

```
src/agent/prompts/
â”œâ”€â”€ prompt_content.py  (pure text, no escaping!)
â”œâ”€â”€ prompt_builder.py  (Builder + Factory patterns)
â””â”€â”€ react_prompt.py    (simple API via factory delegation)
```

**Key Code Pattern**:

```python
# Content: Just plain text, no escaping needed
def get_system_prompt() -> str:
    parts = [
        "Your role...",
        REACT_FORMAT_RULES,
        "Action Input: {\"user_id\": \"...\"}",  # âœ… Natural JSON!
        "Instructions...",
    ]
    return "\n".join(parts)

# Template: Uses SystemMessage, not from_template()
class ReactPromptBuilder(PromptBuilder):
    def build(self) -> ChatPromptTemplate:
        system_prompt = get_system_prompt()  # Pure text
        system_message = SystemMessage(content=system_prompt)  # No {} interpretation!
        return ChatPromptTemplate.from_messages([
            system_message,
            MessagesPlaceholder(variable_name="messages"),
        ])
```

### Checklist for Future LLM Projects

When adding LLM prompts to ANY project:

- [ ] **Separate content and logic**: Different files, never mix
- [ ] **Use SystemMessage**: `SystemMessage(content=...)` NOT `from_template()`
- [ ] **No escaping needed**: If you're using `{{`, you're doing it wrong
- [ ] **Apply Builder + Factory**: For flexibility and testability
- [ ] **Document the architecture**: Reference PROMPT_SOLID_REFACTORING.md

### Complete Documentation & Analysis

For full details with implementation examples and analysis, read these postmortem documents:

1. **`docs/postmortem-litellm-no-tool-results.md`** (25 min read)
   - "No tool results extracted!" error deep analysis
   - Temperature impact on consistency with data
   - Phase 1-4 improvement roadmap
   - Why LiteLLM differs from native Gemini API
   - Key insights for future projects

2. **`docs/postmortem-prompt-escaping-solid-refactoring.md`** (30 min read)
   - JSON escaping problem explanation with real examples
   - Complete SOLID-based solution
   - Builder + Factory pattern implementation
   - Future extension examples (conditional content, custom builders)
   - Prevention checklist

3. **`docs/PROMPT_SOLID_REFACTORING.md`** (Complete Implementation Reference)
   - Before/after architecture comparison
   - Full file structure with complete code
   - Testing results and verification
   - SOLID principles breakdown with code examples
   - Future improvements roadmap

---

## Further Reading

- **User Scenarios**: `docs/user_scenarios_mvp1.md`
- **Setup Template**: `docs/PROJECT_SETUP_PROMPT.md`
- **Contributing**: See git flow above + code quality rules

---

## REQ-Based Development Workflow (for MVP 1.0)

**When to use**: Each user request follows format: `"REQ-X-Y ê¸°ëŠ¥ êµ¬í˜„í•´"` (implement REQ X-Y)

### Command Format

```
User: "REQ-B-A2-Edit-1 ê¸°ëŠ¥ êµ¬í˜„í•´"
Assistant: (Automatically follows 4-phase workflow below)
```

### Phase 1ï¸âƒ£: SPECIFICATION (Parse & Pause for Review)

```
- Extract REQ ID, ìš”êµ¬ì‚¬í•­, ìš°ì„ ìˆœìœ„, Acceptance Criteria from feature_requirement_mvp1.md
- Summarize: intent, constraints, performance goals
- Define: Location (module path), Signature (types, I/O, side effects),
  Behavior (logic, validation), Dependencies, Non-functional (perf/security)
- ğŸ›‘ PAUSE: Present spec, ask "Approved? Continue to Phase 2?"
```

### Phase 2ï¸âƒ£: TEST DESIGN (TDD Before Code)

```
- Create: tests/<domain>/test_<feature>.py
- Design 4-5 test cases:
  âœ“ Happy path (valid inputs)
  âœ“ Input validation errors
  âœ“ Edge cases (DB, timeout, concurrency)
  âœ“ Acceptance criteria verification
- Include REQ ID in docstrings: # REQ: REQ-X-Y-Edit-1
- ğŸ›‘ PAUSE: Present test list, ask "Tests approved? Continue to Phase 3?"
```

### Phase 3ï¸âƒ£: IMPLEMENTATION (Code to Spec)

```
- Write minimal code satisfying spec + tests
- Follow SOLID + conventions from above
- Run: tox -e style && pytest tests/<domain>/test_<feature>.py
- ğŸ›‘ STOP if validation fails; report errors
```

### Phase 4ï¸âƒ£: SUMMARY (Report & Commit)

```
- Modified files + rationale
- Test results (all pass)
- Traceability: REQ â†’ Spec â†’ Tests â†’ Code
- **Create progress file**: docs/progress/REQ-X-Y.md with full Phase 1-4 documentation
  * Include: Requirements, Implementation locations, Test results, Git commit
  * Add REQ traceability table (implementation â†” test coverage)
- **Update progress tracking**: docs/DEV-PROGRESS.md
  * Find REQ row in developer section
  * Change Phase: 0 â†’ 4
  * Change Status: â³ Backlog â†’ âœ… Done
  * Update Notes: Add commit SHA (e.g., "Commit: f5412e9")
- Create git commit:
  * Format: "chore: Update progress tracking for REQ-X-Y completion"
  * Include: progress file creation + DEV-PROGRESS.md update
  * Tag with ğŸ¤– Claude Code marker
```

**Key Principle**: Phase 1-2 pause for review = prevent rework. Spec must be approved before coding.
**Progress Tracking**: Always complete Phase 4 progress files to maintain audit trail & team visibility.

---

## CLI Feature Requirement Workflow

**When to use**: CLI ê¸°ëŠ¥ ì¶”ê°€/ê°œì„ í•  ë•Œ, ëª¨ë“  featureëŠ” requirement ë¨¼ì € ì •ì˜

### Step 1: Requirement ì‘ì„±

**íŒŒì¼**: `docs/CLI-FEATURE-REQUIREMENTS.md`ì— ë‹¤ìŒ í¬ë§·ìœ¼ë¡œ ì¶”ê°€

**í¬ë§·**: `REQ-CLI-[DOMAIN]-[NUMBER]`

- Domain: auth, survey, profile, questions, session, export, ...
- Number: ë„ë©”ì¸ ë‚´ ìˆœë²ˆ (1, 2, 3, ...)

**í…œí”Œë¦¿**:

```markdown
### REQ-CLI-[DOMAIN]-[NUMBER]: [ê¸°ëŠ¥ëª…]

**Description**:
í•œ ë¬¸ì¥ ìš”ì•½

ìƒì„¸ ì„¤ëª… (2-3ì¤„)

**ì‚¬ìš© ì˜ˆ**:
```bash
> command [args]
âœ“ success output
```

**ê¸°ëŒ€ ì¶œë ¥**:

- ì„±ê³µ: ë©”ì‹œì§€ + ë°ì´í„°
- ì‹¤íŒ¨: ì—ëŸ¬ ë©”ì‹œì§€

**ì—ëŸ¬ ì¼€ì´ìŠ¤**:

- Not authenticated â†’ "Please login first"
- API error â†’ ìƒì„¸ ì—ëŸ¬ ë©”ì‹œì§€
- Invalid input â†’ Usage ê°€ì´ë“œ

**Acceptance Criteria**:

- [ ] ëª…ë ¹ì–´ ì •í™• ì‘ë™
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ì™„ë²½
- [ ] ë„ì›€ë§ ëª…í™•

**Priority**: M/H/L
**Dependencies**: [API / Module]
**Status**: â³ Backlog

```

### Step 2-5: REQ-Based Workflow ì ìš©

**Phase 1-4ëŠ” ê¸°ì¡´ CLAUDE.mdì˜ REQ-Based Development Workflowê³¼ ë™ì¼**

```

REQ-CLI-AUTH-1 ê¸°ëŠ¥ êµ¬í˜„í•´
â†“
Phase 1: ìš”êµ¬ì‚¬í•­ ê²€í†  â†’ Approve?
Phase 2: í…ŒìŠ¤íŠ¸ ì„¤ê³„ â†’ Approve?
Phase 3: êµ¬í˜„ + ê²€ì¦
Phase 4: Commit + Progress tracking

```

### CLI Feature ë°œê²¬ ë° ì¶”ê°€ ë°©ë²•

**ë°©ë²•: ì¦‰ì‹œ ì¶”ê°€ (ê¶Œì¥)**

```

ì‚¬ìš©ì: "CLIì— ì„¸ì…˜ ì €ì¥ ê¸°ëŠ¥ì´ í•„ìš”í•´"
â†“

1. docs/CLI-FEATURE-REQUIREMENTS.mdì— REQ-CLI-SESSION-1 ì¶”ê°€
2. Requirement ì •ì˜ (5ë¶„)
3. "REQ-CLI-SESSION-1 ê¸°ëŠ¥ êµ¬í˜„í•´" ìš”ì²­
4. Claudeê°€ 4ë‹¨ê³„ Workflow ì ìš©

```

### CLI Requirement ê´€ë¦¬

**ì¡°ì§**:
- `docs/CLI-FEATURE-REQUIREMENTS.md`: ëª¨ë“  CLI ìš”êµ¬ì‚¬í•­ í†µí•© ê´€ë¦¬
- `docs/DEV-PROGRESS.md`: CLI ì„¹ì…˜ì— ì§„í–‰ ìƒí™© ì¶”ì 
- `docs/progress/REQ-CLI-*.md`: ê° ê¸°ëŠ¥ë³„ Phase 4 documentation

**ì§„í–‰ ì¶”ì **:
- Phase 4 ì™„ë£Œ ì‹œ:
  1. `docs/CLI-FEATURE-REQUIREMENTS.md`ì—ì„œ Status: âœ… Done ë³€ê²½
  2. `docs/DEV-PROGRESS.md`ì˜ CLI ì„¹ì…˜ì—ì„œ Phase 4ë¡œ ë³€ê²½
  3. Commit SHA ê¸°ë¡

---

**Forcing Function Principle**: 3-4 intuitive commands (dev.sh, commit.sh, tox) reduce learning curve & execution variance. See `docs/PROJECT_SETUP_PROMPT.md` for details.

---

## ğŸ¯ CURRENT STATUS & NEXT TASKS

### ğŸ” [2025-11-25] CLI Architecture Refactoring Discovery

**ë¬¸ì œ ë°œê²¬**:
- CLIì™€ Docker Backendê°€ **ì„œë¡œ ë‹¤ë¥¸ PostgreSQL DB**ì— ì ‘ê·¼
  - CLI: `localhost:5432/sleassem_dev` (ë¡œì»¬ WSL)
  - Backend: Docker ë‚´ë¶€ `slea-db:5432` (í¬íŠ¸ 5433ìœ¼ë¡œ ë…¸ì¶œ)
- `profile update_survey` ì„±ê³µ (Docker API â†’ Docker DB)
- `questions generate` ì‹¤íŒ¨ (CLIê°€ ë¡œì»¬ DB í™•ì¸ â†’ ë°ì´í„° ì—†ìŒ)

**ê·¼ë³¸ ì›ì¸**: `src/cli/actions/questions.py`ì˜ 8ê°œ í•¨ìˆ˜ê°€ `SessionLocal()`ë¡œ ì§ì ‘ DB ì ‘ê·¼
```python
# âŒ ë¬¸ì œ ìˆëŠ” ì½”ë“œë“¤:
_get_latest_survey()          # line 29
_get_latest_session()         # line 55
_get_latest_question()        # line 76
_get_all_questions_in_session()  # line 127
_get_unscored_answers()       # line 159
_get_question_type()          # line 195
_get_answer_info()            # line 250
show_session_questions()      # line 706
```

**í•´ê²°ì±…**: CLIê°€ REST APIë§Œ í˜¸ì¶œí•˜ë„ë¡ ë¦¬íŒ©í† ë§ (2-phase ì‘ì—…)

---

### ğŸ“‹ REQ-CLI-QUESTIONS-1: CLI DB ì§ì ‘ ì ‘ê·¼ ì œê±° ë° REST API ë§ˆì´ê·¸ë ˆì´ì…˜

**Phase 0: ì„ í–‰ ì‘ì—… (ë‚´ì¼)**

**1ë‹¨ê³„: Backend API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ (~1ì‹œê°„)**

í•„ìš”í•œ ìƒˆë¡œìš´ API (5ê°œ):
- `GET /profile/survey` âœ… ì´ë¯¸ ìˆìŒ (profile.py)
- `GET /questions/session/latest` âŒ ì—†ìŒ
- `GET /questions/{question_id}` âŒ ì—†ìŒ
- `GET /questions/session/{session_id}/questions` âŒ ì—†ìŒ
- `GET /questions/session/{session_id}/unscored` âŒ ì—†ìŒ

ìœ„ì¹˜: `src/backend/api/questions.py`

**2ë‹¨ê³„: CLI ë¦¬íŒ©í† ë§ (~1ì‹œê°„)**

ì œê±°í•  í•¨ìˆ˜ë“¤:
```python
# ê° í•¨ìˆ˜ë¥¼ client.make_request() í˜¸ì¶œë¡œ ë³€ê²½
_get_latest_survey()       â†’ GET /profile/survey
_get_latest_session()      â†’ GET /questions/session/latest
_get_latest_question()     â†’ GET /questions/{question_id}
_get_all_questions_in_session() â†’ GET /questions/session/{session_id}/questions
_get_unscored_answers()    â†’ GET /questions/session/{session_id}/unscored
_get_question_type()       â†’ GET /questions/{question_id}
_get_answer_info()         â†’ GET /questions/{question_id}/answer
show_session_questions()   â†’ GET /questions/session/{session_id}/questions
```

ì œê±°: `from src.backend.database import SessionLocal` import

---

### âœ… ê¸°ì¡´ High-Priority Tasks (ë¯¸ì—°ê¸°)

### Task 1: REQ-A-Agent-Backend-1 (Mock â†’ Real Agent í†µí•©) â­
- **File**: `src/backend/services/question_gen_service.py` (ìˆ˜ì •)
- **Status**: â³ Not started
- **Duration**: ~1.5ì‹œê°„
- **Spec Location**: `docs/AGENT-TEST-SCENARIO.md` lines 471-555

### Task 2 (Optional): REQ-A-Agent-Backend-2 (ScoringService í†µí•©)
- **File**: `src/backend/services/scoring_service.py`
- **Status**: â³ Not started
- **Duration**: ~1ì‹œê°„
- **Spec Location**: `docs/AGENT-TEST-SCENARIO.md` lines 517-555

---

## ğŸ“š Documentation References (Already Exist)
**Do NOT regenerate these** - they are already complete:
- `docs/TOOL_DEFINITIONS_SUMMARY.md` - Complete tool signatures & details
- `docs/TOOL_QUICK_REFERENCE.md` - Quick examples & validation rules
- `docs/TOOL_DOCUMENTATION_INDEX.md` - Navigation & troubleshooting
- `docs/AGENT-TEST-SCENARIO.md` - Full phase planning (REQ-A-Agent-*)

**Just reference them when implementing!**

---

## ğŸš€ Quick Start After Context Gap

1. Read this section first (2 min)
2. Run: `git log --oneline -10` to see recent commits
3. Start with Task 1 (REQ-A-Agent-Backend-1) in `docs/AGENT-TEST-SCENARIO.md` lines 471-555
4. Use TOOL documentation (don't regenerate - it already exists)
5. Create progress file in `docs/progress/REQ-A-Agent-Backend-1.md` after Phase 4
