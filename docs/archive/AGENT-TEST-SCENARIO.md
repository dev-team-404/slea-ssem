# Agent í…ŒìŠ¤íŠ¸ & ë°±ì—”ë“œ í†µí•© ì‹œë‚˜ë¦¬ì˜¤

**ë¬¸ì„œ ì‘ì„± ë‚ ì§œ**: 2025-11-11
**ë²„ì „**: 1.0
**ìƒíƒœ**: ğŸ‘¨â€ğŸ’¼ ê²€í†  ëŒ€ê¸° ì¤‘ (ë™ë£Œ A, B ì˜ê²¬ í†µí•©)

---

## ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ë™ë£Œ ì˜ê²¬ ìš”ì•½](#ë™ë£Œ-ì˜ê²¬-ìš”ì•½)
3. [REQ ID ì²´ê³„](#req-id-ì²´ê³„)
4. [Phaseë³„ ì„¸ë¶€ ê³„íš](#phaseë³„-ì„¸ë¶€-ê³„íš)
5. [íƒ€ì„ë¼ì¸ & ì§„í–‰ ì¶”ì ](#íƒ€ì„ë¼ì¸--ì§„í–‰-ì¶”ì )

---

## ê°œìš”

### í˜„ì¬ ìƒí™©

- **ì™„ì„±ë¨**: Agent êµ¬í˜„ (`src/agent/llm_agent.py` 900+ì¤„)
- **ì™„ì„±ë¨**: Agent í…ŒìŠ¤íŠ¸ (`tests/agent/test_llm_agent.py` 1290ì¤„, Mock ê¸°ë°˜)
- **ì™„ì„±ë¨**: FastAPI ë°±ì—”ë“œ (Mock ë°ì´í„° ì‚¬ìš©)
- **í•„ìš”í•¨**: ì‹¤ì œ LLM í†µí•©, ë°±ì—”ë“œ ì—°ê²°, E2E í…ŒìŠ¤íŠ¸

### ëª©í‘œ

1. âœ… **Phase 0**: Agentê°€ ì‹¤ì œ Google Gemini LLMê³¼ ì •ìƒ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
2. âœ… **Phase 1**: CLIì—ì„œ ì§ì ‘ Agentë¥¼ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆëŠ” ëª…ë ¹ì–´ ì¶”ê°€
3. âœ… **Phase 2**: FastAPI ë°±ì—”ë“œê°€ Agentë¥¼ í˜¸ì¶œí•˜ë„ë¡ í†µí•©
4. âœ… **Phase 3**: ì „ì²´ workflow (Frontend â†’ Agent â†’ Backend â†’ DB) í…ŒìŠ¤íŠ¸

### ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ìµœì¢… ì™„ì„±ëœ ì›Œí¬í”Œë¡œìš°                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  Frontend (ë ˆë²¨í…ŒìŠ¤íŠ¸ ë²„íŠ¼)                                   â”‚
â”‚         â†“                                                     â”‚
â”‚  FastAPI Endpoint (/api/v1/items/generate)                   â”‚
â”‚         â†“                                                     â”‚
â”‚  QuestionGenerationService.generate_questions()             â”‚
â”‚         â†“                                                     â”‚
â”‚  ItemGenAgent.generate_questions()  â† Agent í˜¸ì¶œ             â”‚
â”‚         â†“                                                     â”‚
â”‚  Google Gemini LLM + FastMCP Tools (1-5)                    â”‚
â”‚         â†“                                                     â”‚
â”‚  Database (test_sessions, test_questions)                   â”‚
â”‚         â†“                                                     â”‚
â”‚  HTTP Response (JSON with generated items)                  â”‚
â”‚                                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                               â”‚
â”‚  ë‹¨ì¼ ì±„ì  ì›Œí¬í”Œë¡œìš°:                                        â”‚
â”‚  User Answer â†’ Tool 6 (score_and_explain) â†’ Score + Explanation
â”‚                                                               â”‚
â”‚  ë°°ì¹˜ ì±„ì  ì›Œí¬í”Œë¡œìš°:                                        â”‚
â”‚  Multiple Answers â†’ Tool 6 (Parallel) â†’ Batch Results       â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ë™ë£Œ ì˜ê²¬ ìš”ì•½

### ë™ë£Œ A (CLI êµ¬ì¡° ê°œì„ ) âœ…

**í•µì‹¬**: AgentëŠ” SSE ì„œë²„ê°€ ì•„ë‹ˆë¼ ì¼íšŒì„± ê°ì²´. CLI ëª…ë ¹ì–´ë¡œ ì§ì ‘ í˜¸ì¶œ ê°€ëŠ¥.

**ì£¼ìš” ì œì•ˆ**:

- `./tools/dev.sh cli agent generate-questions --survey-id "..."` í˜•íƒœì˜ ëª…ë ¹ì–´ ì¶”ê°€
- ê¸°ì¡´ CLI êµ¬ì¡° (`src/cli/main.py`, `src/cli/actions/`) í™œìš©
- Phase 1ì—ì„œ ì‹¤í–‰

### ë™ë£Œ B (Agent ê²€ì¦ & ë°±ì—”ë“œ í†µí•©) âœ…

**í•µì‹¬**: Agent ë™ì‘ í™•ì¸ â†’ Backend í†µí•© ìˆœì„œë¡œ ì§„í–‰

**ì£¼ìš” ì œì•ˆ**:

- Phase 0: Python ìŠ¤í¬ë¦½íŠ¸ë¡œ Agent ìµœì†Œ ì¬í˜„ (inline script)
- `LANGCHAIN_DEBUG=1` ë˜ëŠ” `LANGCHAIN_TRACING_V2=1`ë¡œ Thoughtâ†’Actionâ†’Observation ì¶”ì 
- Phase 2: `QuestionGenerationService`ì˜ Mockì„ `await create_agent()` í˜¸ì¶œë¡œ ë³€ê²½
- SSE/Streamingì€ ì„ íƒì‚¬í•­ (`astream_events` ì§€ì›)

---

## REQ ID ì²´ê³„

### REQ ID ê·œì¹™ (CLAUDE.md ì¤€ìˆ˜)

| í¬ë§· | ìš©ë„ | ì˜ˆì‹œ |
|------|------|------|
| `REQ-A-[Feature]-[Number]` | Agent ê´€ë ¨ | `REQ-A-Agent-Sanity-0` |
| `REQ-CLI-[Domain]-[Number]` | CLI ê¸°ëŠ¥ | `REQ-CLI-Agent-1` |
| `REQ-B-[Feature]-[Number]` | Backend ê´€ë ¨ | `REQ-B-Scoring-1` |

### ì„¸ë¶€ REQ ID ì •ì˜

#### ğŸ”µ Phase 0: Agent ê¸°ë³¸ ë™ì‘ í™•ì¸

**REQ-A-Agent-Sanity-0: Agent ê¸°ë³¸ ë™ì‘ ê²€ì¦ (Sanity Check)**

```yaml
ì„¤ëª…: ì‹¤ì œ Google Gemini LLMì„ ì‚¬ìš©í•˜ì—¬ Agentê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
ì‚¬ìš© ì˜ˆ:
  export GEMINI_API_KEY="your_key"
  export LANGCHAIN_DEBUG=1
  uv run python scripts/test_agent_sanity_check.py
ê¸°ëŒ€ ì¶œë ¥:
  âœ… Agent initialized
  ğŸ“ Generating questions...
  [Tool 1 í˜¸ì¶œ] get_user_profile
  [Tool 3 í˜¸ì¶œ] get_difficulty_keywords
  [Tool 5 í˜¸ì¶œ] save_generated_question (3 items)
  âœ… Generation Complete: 3 items generated

Acceptance Criteria:
  - [ ] GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ í™•ì¸
  - [ ] Agent ì´ˆê¸°í™” ì„±ê³µ
  - [ ] LLM API ì—°ê²° ì„±ê³µ
  - [ ] Tools í˜¸ì¶œ í™•ì¸ (LANGCHAIN_DEBUG ì¶œë ¥)
  - [ ] ë¬¸í•­ 3ê°œ ì´ìƒ ìƒì„±
  - [ ] JSON ì‘ë‹µ íŒŒì‹± ì„±ê³µ

Priority: ğŸ”´ HIGH (ëª¨ë“  ë‹¤ìŒ ë‹¨ê³„ì˜ ê¸°ì´ˆ)
Dependencies: []
Status: â³ Backlog
```

---

#### ğŸŸ¢ Phase 1: CLI ëª…ë ¹ì–´ í™•ì¥ (ê³„ì¸µì  êµ¬ì¡°)

### CLI ë©”ë‰´ êµ¬ì¡° (ìµœì¢…)

```
slea-ssem CLI ğŸ“‹

Commands:

  survey                          ìê¸°í‰ê°€ Survey ê´€ë¦¬
    schema                        Survey í¼ ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
    submit                        Survey ë°ì´í„° ì œì¶œ ë° ì €ì¥

  agent                           Agent ë¬¸í•­ ìƒì„± & ì±„ì 
    generate-questions            ğŸ“ ë¬¸í•­ ìƒì„± (Tool 1-5 ìë™ ì²´ì¸)
    score-answer                  ğŸ“‹ ë‹µë³€ ì±„ì  (Tool 6)
    batch-score                   ğŸ“Š ë°°ì¹˜ ì±„ì  (Tool 6 ë³‘ë ¬)
    tools                         ğŸ”§ ê°œë³„ Tool ë””ë²„ê¹…
      tool-1                      Tool 1: User Profile ì¡°íšŒ
      tool-2                      Tool 2: ì§ˆë¬¸ í…œí”Œë¦¿ ê²€ìƒ‰
      tool-3                      Tool 3: ë‚œì´ë„ë³„ í‚¤ì›Œë“œ ì¡°íšŒ
      tool-4                      Tool 4: ë¬¸í•­ í’ˆì§ˆ ê²€ì¦
      tool-5                      Tool 5: ë¬¸í•­ ì €ì¥
      tool-6                      Tool 6: ì±„ì  & í•´ì„¤

  clear                           í„°ë¯¸ë„ í™”ë©´ ì •ë¦¬
  exit                            CLI ì¢…ë£Œ
  help                            ë„ì›€ë§ í‘œì‹œ
```

---

**REQ-CLI-Agent-1: agent ëª…ë ¹ ê·¸ë£¹ ë° ê³„ì¸µì  ë©”ë‰´ êµ¬ì¡° êµ¬í˜„**

```yaml
ì„¤ëª…: CLIì— agent ëª…ë ¹ ê·¸ë£¹ ì¶”ê°€ (ê³„ì¸µì  êµ¬ì¡°)
      - agent generate-questions (ì›Œí¬í”Œë¡œìš°)
      - agent score-answer (ë‹¨ì¼ ì±„ì )
      - agent batch-score (ë°°ì¹˜ ì±„ì )
      - agent tools (ê°œë³„ Tool ë””ë²„ê¹…)

ì‚¬ìš© ì˜ˆ:
  ./tools/dev.sh cli agent --help
  ./tools/dev.sh cli agent tools --help
  ./tools/dev.sh cli agent tools tool-1 --help

ê¸°ëŒ€ ì¶œë ¥ (agent --help):
  Usage: agent [OPTIONS] COMMAND [ARGS]...

  Agent-based question generation and scoring

  Options:
    --help  Show this message and exit.

  Commands:
    batch-score           ğŸ“Š ë°°ì¹˜ ì±„ì  (ë³µìˆ˜ ë‹µë³€, ë³‘ë ¬)
    generate-questions    ğŸ“ ë¬¸í•­ ìƒì„± (Tool 1-5 ì²´ì¸)
    score-answer          ğŸ“‹ ë‹µë³€ ì±„ì  (Tool 6)
    tools                 ğŸ”§ ê°œë³„ Tool ë””ë²„ê¹…

Acceptance Criteria:
  - [ ] agent ëª…ë ¹ ê·¸ë£¹ ë“±ë¡
  - [ ] 4ê°œ í•˜ìœ„ ëª…ë ¹ ì¸ì‹ (generate-questions, score-answer, batch-score, tools)
  - [ ] agent --help ì‹¤í–‰ ê°€ëŠ¥
  - [ ] agent [command] --help ì‹¤í–‰ ê°€ëŠ¥
  - [ ] ê° ëª…ë ¹ ì„¤ëª… ëª…í™•
  - [ ] tools í•˜ìœ„ì— tool-1~6 ë¦¬ìŠ¤íŠ¸ í‘œì‹œ

Priority: ğŸ”´ HIGH
Dependencies: [REQ-A-Agent-Sanity-0]
Status: â³ Backlog
```

**REQ-CLI-Agent-2: agent generate-questions ëª…ë ¹ (ì „ì²´ íŒŒì´í”„ë¼ì¸)**

```yaml
ì„¤ëª…: Tool 1-5ë¥¼ ìë™ìœ¼ë¡œ ì²´ì¸í•˜ì—¬ ë¬¸í•­ì„ ìƒì„±í•˜ëŠ” ëª…ë ¹
      ì´ ëª…ë ¹ì€ ë°±ì—”ë“œì˜ /api/v1/items/generateì™€ ë™ì¼í•œ ë™ì‘ ìˆ˜í–‰

ì‚¬ìš© ì˜ˆ:
  # Round 1 (ê¸°ë³¸)
  ./tools/dev.sh cli agent generate-questions --survey-id "survey_123"

  # Round 2 (ì ì‘í˜•, ì´ì „ ë‹µë³€ í¬í•¨)
  ./tools/dev.sh cli agent generate-questions \
    --survey-id "survey_123" \
    --round 2 \
    --prev-answers '[{"item_id":"q1","score":85},{"item_id":"q2","score":60}]'

ê¸°ëŒ€ ì¶œë ¥:
  ğŸš€ Initializing Agent... (GEMINI_API_KEY required)
  âœ… Agent initialized

  ğŸ“ Generating questions...
     survey_id=survey_123, round=1

  âœ… Generation Complete
     round_id: round_20251111_123456_001
     items generated: 3
     failed: 0
     agent_steps: 12

  ğŸ“‹ Generated Items:
  â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”“
  â”ƒ ID         â”ƒ Type        â”ƒ Difficult â”ƒ Validation
  â”£â”â”â”â”â”â”â”â”â”â”â”â”â•‹â”â”â”â”â”â”â”â”â”â”â”â”â”â•‹â”â”â”â”â”â”â”â”â”â”â”â•‹â”â”â”â”â”â”â”â”â”â”â”«
  â”ƒ q_00001... â”ƒ short_answerâ”ƒ 5        â”ƒ 0.92
  â”ƒ q_00002... â”ƒ mult_choice â”ƒ 7        â”ƒ 0.89
  â”ƒ q_00003... â”ƒ true_false  â”ƒ 3        â”ƒ 0.95
  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”›â”â”â”â”â”â”â”â”â”â”â”â”â”â”›â”â”â”â”â”â”â”â”â”â”â”â”›â”â”â”â”â”â”â”â”â”â”â”›

  ğŸ“„ First Item Details:
     Stem: What is a transformer in NLP?
     Answer Schema: keyword_match
     Keywords: [transformer, attention, neural]

Acceptance Criteria:
  - [ ] --survey-id íŒŒë¼ë¯¸í„° í•„ìˆ˜
  - [ ] --round íŒŒë¼ë¯¸í„° ê¸°ë³¸ê°’ 1 (1~2)
  - [ ] --prev-answers JSON íŒŒì‹± (Round 2 ìš©)
  - [ ] LANGCHAIN_DEBUG í™˜ê²½ë³€ìˆ˜ ì§€ì›
  - [ ] Agent í˜¸ì¶œ ì„±ê³µ
  - [ ] ë¬¸í•­ 3ê°œ ì´ìƒ ìƒì„±
  - [ ] Rich Table í¬ë§· ì¶œë ¥
  - [ ] round_id, agent_steps, failed_count í‘œì‹œ
  - [ ] ì—ëŸ¬ ì²˜ë¦¬ (GEMINI_API_KEY ì—†ìŒ, API íƒ€ì„ì•„ì›ƒ, íŒŒì‹± ì—ëŸ¬)
  - [ ] Markdown ë¬¸ë²• ì‚¬ìš© (Tool 1-5 ë‹¨ê³„ ì¶œë ¥ í•„ìš”ì‹œ)

Priority: ğŸ”´ HIGH
Dependencies: [REQ-CLI-Agent-1, REQ-A-Agent-Sanity-0]
Status: â³ Backlog
```

**REQ-CLI-Agent-3: agent score-answer ëª…ë ¹ (ë‹¨ì¼ ë‹µë³€ ì±„ì )**

```yaml
ì„¤ëª…: Tool 6ì„ í˜¸ì¶œí•˜ì—¬ ë‹¨ì¼ ë‹µë³€ì„ ì±„ì í•˜ëŠ” ëª…ë ¹

ì‚¬ìš© ì˜ˆ:
  ./tools/dev.sh cli agent score-answer \
    --round-id "round_123" \
    --item-id "q_001" \
    --user-answer "Transformers use attention mechanism"

  # ì¶”ê°€ ì •ë³´ í¬í•¨
  ./tools/dev.sh cli agent score-answer \
    --round-id "round_123" \
    --item-id "q_001" \
    --user-answer "My answer" \
    --question-type "short_answer" \
    --correct-answer "Expected answer" \
    --correct-keywords "key1,key2,key3"

ê¸°ëŒ€ ì¶œë ¥:
  ğŸš€ Initializing Agent...
  âœ… Agent initialized

  ğŸ“‹ Scoring answer...
     item_id=q_001, type=short_answer, response_time=5000ms

  âœ… Scoring Complete
     score: 75.5 / 100
     correct: âœ“ (partial)
     explanation: Good understanding of transformer attention mechanism...

  ğŸ“Š Details:
     Extracted Keywords: [transformer, attention, mechanism]
     Feedback: Consider mentioning positional encoding for completeness
     Graded At: 2025-11-11T14:30:00Z

Acceptance Criteria:
  - [ ] --round-id íŒŒë¼ë¯¸í„° í•„ìˆ˜
  - [ ] --item-id íŒŒë¼ë¯¸í„° í•„ìˆ˜
  - [ ] --user-answer íŒŒë¼ë¯¸í„° í•„ìˆ˜
  - [ ] --question-type ê¸°ë³¸ê°’ 'short_answer'
  - [ ] Score 0-100 ë²”ìœ„ í‘œì‹œ
  - [ ] is_correct ë¶ˆë¦°ê°’ í‘œì‹œ (âœ“/âœ—)
  - [ ] explanation ë¬¸ìì—´ ì¶œë ¥
  - [ ] extracted_keywords ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
  - [ ] feedback ì˜µì…˜ê°’ í‘œì‹œ (ìˆì„ ê²½ìš°)
  - [ ] ì—ëŸ¬ ì²˜ë¦¬ (í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½, LLM ì˜¤ë¥˜)

Priority: ğŸŸ¡ MEDIUM
Dependencies: [REQ-CLI-Agent-1, REQ-A-Agent-Sanity-0]
Status: â³ Backlog
```

**REQ-CLI-Agent-4: agent batch-score ëª…ë ¹ (ë°°ì¹˜ ì±„ì )**

```yaml
ì„¤ëª…: ì—¬ëŸ¬ ë‹µë³€ì„ ë³‘ë ¬ë¡œ ì±„ì í•˜ëŠ” ëª…ë ¹ (Tool 6 ë³‘ë ¬ í˜¸ì¶œ)

ì‚¬ìš© ì˜ˆ:
  ./tools/dev.sh cli agent batch-score \
    --round-id "round_123" \
    --answers-file "answers.json"

  # answers.json í˜•ì‹:
  {
    "answers": [
      {"item_id": "q_001", "user_answer": "Answer 1", "response_time_ms": 5000},
      {"item_id": "q_002", "user_answer": "Answer 2", "response_time_ms": 4000},
      {"item_id": "q_003", "user_answer": "Answer 3", "response_time_ms": 6000}
    ]
  }

ê¸°ëŒ€ ì¶œë ¥:
  ğŸš€ Initializing Agent...
  âœ… Agent initialized

  ğŸ“Š Batch Scoring...
     round_id=round_123, items=3

  â³ Processing (parallel)...
  âœ… q_001: 90.0 âœ“
  âœ… q_002: 75.5 âœ“ (partial)
  âœ… q_003: 45.0 âœ—

  ğŸ“ˆ Batch Results:
  â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
  â”ƒ Item   â”ƒ Scoreâ”ƒ Correctâ”ƒ Keywordsâ”ƒ
  â”£â”â”â”â”â”â”â”â”â•‹â”â”â”â”â”â”â•‹â”â”â”â”â”â”â”â•‹â”â”â”â”â”â”â”â”â”â”«
  â”ƒ q_001  â”ƒ 90.0 â”ƒ âœ“      â”ƒ [k1,k2]â”ƒ
  â”ƒ q_002  â”ƒ 75.5 â”ƒ ~ (partial) â”ƒ [k3]â”ƒ
  â”ƒ q_003  â”ƒ 45.0 â”ƒ âœ—      â”ƒ []     â”ƒ
  â”—â”â”â”â”â”â”â”â”â”›â”â”â”â”â”â”â”›â”â”â”â”â”â”â”â”›â”â”â”â”â”â”â”â”â”â”›

  ğŸ“Š Round Statistics:
     Round Score: 70.2 (average)
     Correct Count: 1 + 1 partial = ~2
     Total Count: 3
     Avg Response Time: 5000ms

Acceptance Criteria:
  - [ ] --round-id íŒŒë¼ë¯¸í„° í•„ìˆ˜
  - [ ] --answers-file íŒŒë¼ë¯¸í„° í•„ìˆ˜ (JSON íŒŒì¼)
  - [ ] ë³‘ë ¬ ì²˜ë¦¬ (ìˆœì°¨ ì•„ë‹˜)
  - [ ] ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ì¶œë ¥
  - [ ] ìµœì¢… í†µê³„ í‘œì‹œ (round_score, correct_count, avg_time)
  - [ ] Rich Tableë¡œ ê²°ê³¼ í‘œì‹œ
  - [ ] ë¶€ë¶„ ì •ë‹µ ì²˜ë¦¬ (partial í‘œì‹œ)
  - [ ] ì—ëŸ¬ ì²˜ë¦¬ (íŒŒì¼ ì—†ìŒ, JSON íŒŒì‹± ì—ëŸ¬)

Priority: ğŸŸ¡ MEDIUM
Dependencies: [REQ-CLI-Agent-3, REQ-A-Agent-Sanity-0]
Status: â³ Backlog
```

**REQ-CLI-Agent-5: agent tools [tool-name] ëª…ë ¹ (ê°œë³„ Tool ë””ë²„ê¹…)**

```yaml
ì„¤ëª…: ê° Toolì„ ê°œë³„ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë””ë²„ê¹… ëª…ë ¹ì–´
      Tool 1-5: ê°œë³„ ì…ë ¥/ì¶œë ¥ í™•ì¸
      Tool 6: ì±„ì  ë‹¨ê³„ë³„ ê²€ì¦

í•˜ìœ„ ëª…ë ¹:
  tool-1 (get-user-profile)
  tool-2 (search-templates)
  tool-3 (get-keywords)
  tool-4 (validate-question)
  tool-5 (save-question)
  tool-6 (score-explain)

ì‚¬ìš© ì˜ˆ:
  # Tool 1: User Profile ì¡°íšŒ
  ./tools/dev.sh cli agent tools tool-1 --survey-id "survey_123"

  # Tool 3: í‚¤ì›Œë“œ ì¡°íšŒ
  ./tools/dev.sh cli agent tools tool-3 \
    --user-level "intermediate" \
    --difficulty 5 \
    --category "AI"

  # Tool 6: ë‹¨ì¼ ì±„ì  (ë””ë²„ê¹…)
  ./tools/dev.sh cli agent tools tool-6 \
    --question-type "short_answer" \
    --user-answer "my answer" \
    --correct-keywords "key1,key2"

ê¸°ëŒ€ ì¶œë ¥ (Tool 1):
  ğŸ”§ Testing Tool 1: get_user_profile

  Input:
    survey_id: survey_123

  Output:
  {
    "user_level": "intermediate",
    "experience_years": 5,
    "interests": ["AI", "NLP"],
    "previous_scores": [85, 90, 78]
  }

  âœ… Tool execution successful

ê¸°ëŒ€ ì¶œë ¥ (Tool 6):
  ğŸ”§ Testing Tool 6: score_and_explain

  Input:
    question_type: short_answer
    user_answer: my answer
    correct_keywords: [key1, key2]

  Output:
  {
    "is_correct": true,
    "score": 85.0,
    "explanation": "Good answer with keywords...",
    "extracted_keywords": ["key1", "key2"],
    "feedback": "Could improve by...",
    "graded_at": "2025-11-11T14:30:00Z"
  }

  âœ… Tool execution successful

Acceptance Criteria:
  - [ ] 6ê°œ Toolë³„ ëª…ë ¹ì–´ êµ¬í˜„ (tool-1~6)
  - [ ] ê° Toolì˜ ì…ë ¥ íŒŒë¼ë¯¸í„° ëª…ì‹œ
  - [ ] JSON í¬ë§·ìœ¼ë¡œ ì¶œë ¥
  - [ ] ì‹¤í–‰ ì„±ê³µ/ì‹¤íŒ¨ ìƒíƒœ í‘œì‹œ
  - [ ] ê° Toolì— --help ì§€ì›
  - [ ] ì—ëŸ¬ ì²˜ë¦¬ ë° ë©”ì‹œì§€ ì¶œë ¥
  - [ ] Tool ì‹¤í–‰ ì‹œê°„ í‘œì‹œ (diagnosticìš©)

Priority: ğŸŸ¡ MEDIUM (ê°œë°œì ë””ë²„ê¹… ëª©ì )
Dependencies: [REQ-CLI-Agent-1]
Status: â³ Backlog
```

---

#### ğŸŸ£ Phase 2: FastAPI ë°±ì—”ë“œ í†µí•©

**REQ-A-Agent-Backend-1: QuestionGenerationService Agent í†µí•©**

```yaml
ì„¤ëª…: QuestionGenerationService.generate_questions()ê°€ Mock ë°ì´í„° ëŒ€ì‹  ì‹¤ì œ Agentë¥¼ í˜¸ì¶œ
í˜„ì¬: Mock ë°ì´í„° ë°˜í™˜
ë³€ê²½: await create_agent().generate_questions() í˜¸ì¶œ

ìˆ˜ì • ìœ„ì¹˜:
  - src/backend/services/question_gen_service.py (generate_questions ë©”ì„œë“œ)

ì½”ë“œ ë³€ê²½:
  # Before (í˜„ì¬)
  def generate_questions(self, survey_id: str, round_num: int):
      return mock_questions  # Mock ë°ì´í„°

  # After (ë³€ê²½ í›„)
  async def generate_questions(self, survey_id: str, round_num: int):
      agent = await create_agent()
      request = GenerateQuestionsRequest(
          survey_id=survey_id,
          round_idx=round_num,
          prev_answers=self._get_previous_answers(survey_id, round_num-1)
      )
      response = await agent.generate_questions(request)
      # Save to DB
      self._save_to_db(response)
      return response

Acceptance Criteria:
  - [ ] generate_questionsì´ asyncë¡œ ë³€ê²½
  - [ ] create_agent() í˜¸ì¶œ ì„±ê³µ
  - [ ] GenerateQuestionsRequest ìƒì„± ë° ì „ë‹¬
  - [ ] ì´ì „ ë¼ìš´ë“œ ë‹µë³€ (prev_answers) ì¡°íšŒ
  - [ ] Agent ì‘ë‹µì„ DBì— ì €ì¥
  - [ ] ê¸°ì¡´ API ì‘ë‹µ í¬ë§· ìœ ì§€
  - [ ] ì—ëŸ¬ ì²˜ë¦¬ (LLM íƒ€ì„ì•„ì›ƒ, DB ì˜¤ë¥˜ ë“±)
  - [ ] íƒ€ì… íŒíŠ¸ ì™„ë²½
  - [ ] Docstring ì‘ì„±
  - [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼

Priority: ğŸ”´ HIGH (ê°€ì¥ ì¤‘ìš”í•œ í†µí•©)
Dependencies: [REQ-CLI-Agent-2, REQ-A-Agent-Sanity-0]
Status: â³ Backlog
```

**REQ-A-Agent-Backend-2: ScoringService Agent Tool 6 í†µí•©**

```yaml
ì„¤ëª…: ScoringService.score_answer()ê°€ Mock ëŒ€ì‹  Agent Tool 6ë¥¼ í˜¸ì¶œ
í˜„ì¬: Mock ì±„ì  (ì •í™• ë§¤ì¹­ë§Œ)
ë³€ê²½: await create_agent().score_and_explain() í˜¸ì¶œ

ìˆ˜ì • ìœ„ì¹˜:
  - src/backend/services/scoring_service.py (score_answer ë©”ì„œë“œ)

ì½”ë“œ ë³€ê²½:
  async def score_answer(self, session_id: str, question_id: str, user_answer: str):
      agent = await create_agent()
      request = ScoreAnswerRequest(
          round_id=session_id,
          item_id=question_id,
          user_answer=user_answer,
          question_type=question.item_type,
          correct_answer=question.correct_answer,
      )
      response = await agent.score_and_explain(request)
      self._save_to_db(response)
      return response

Acceptance Criteria:
  - [ ] score_answerì´ asyncë¡œ ë³€ê²½
  - [ ] create_agent() í˜¸ì¶œ
  - [ ] ScoreAnswerRequest êµ¬ì„± (ì§ˆë¬¸ ì •ë³´ í¬í•¨)
  - [ ] Tool 6 ì‘ë‹µ ì²˜ë¦¬ (score, explanation, keywords)
  - [ ] ì±„ì  ê²°ê³¼ DB ì €ì¥
  - [ ] ê¸°ì¡´ ScoringService ì¸í„°í˜ì´ìŠ¤ ìœ ì§€
  - [ ] ì—ëŸ¬ ì²˜ë¦¬ (LLM ì˜¤ë¥˜, ì§ˆë¬¸ ì—†ìŒ ë“±)
  - [ ] ë°°ì¹˜ ì±„ì ë„ ì§€ì› (submit_answers)
  - [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼

Priority: ğŸŸ¡ MEDIUM (Phase 2ì˜ ì„ íƒì‚¬í•­)
Dependencies: [REQ-CLI-Agent-3, REQ-A-Agent-Sanity-0]
Status: â³ Backlog
```

---

#### ğŸŸ  Phase 3: E2E í†µí•© í…ŒìŠ¤íŠ¸

**REQ-A-Agent-Integration-1: E2E í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸**

```yaml
ì„¤ëª…: ì „ì²´ workflow (CLI â†’ FastAPI â†’ Agent â†’ DB) í†µí•© í…ŒìŠ¤íŠ¸
í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:
  1. CLIì—ì„œ ë¬¸í•­ ìƒì„± ìš”ì²­
  2. FastAPI ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ
  3. Agentê°€ LLM í˜¸ì¶œ
  4. DBì— ì €ì¥
  5. ì±„ì  ì›Œí¬í”Œë¡œìš°
  6. ë°°ì¹˜ ì±„ì 

í…ŒìŠ¤íŠ¸ ìœ„ì¹˜:
  - tests/integration/test_agent_backend_e2e.py

í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
  1. test_generate_questions_e2e
     - Flow: API â†’ Service â†’ Agent â†’ DB
     - Verify: ë¬¸í•­ 3ê°œ ìƒì„±, DB ì €ì¥, ì‘ë‹µ í¬ë§·

  2. test_score_single_answer_e2e
     - Flow: API â†’ Service â†’ Tool 6 â†’ DB
     - Verify: ì ìˆ˜, ì„¤ëª…, í‚¤ì›Œë“œ ì¶”ì¶œ

  3. test_batch_scoring_e2e
     - Flow: API â†’ Service â†’ Tool 6 (Parallel) â†’ DB
     - Verify: ë°°ì¹˜ ê²°ê³¼, ë¼ìš´ë“œ í†µê³„

  4. test_adaptive_questioning_e2e
     - Flow: Round 1 â†’ Score â†’ Round 2 (ë‚œì´ë„ ì¡°ì •)
     - Verify: ë‚œì´ë„ ë³€í™”

  5. test_error_handling_e2e
     - GEMINI_API_KEY ì—†ìŒ
     - LLM íƒ€ì„ì•„ì›ƒ
     - DB ì˜¤ë¥˜

Acceptance Criteria:
  - [ ] 4ê°œ ì´ìƒì˜ í†µí•© í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
  - [ ] ê° í…ŒìŠ¤íŠ¸ê°€ ì‹¤ì œ DB ì‚¬ìš© (í…ŒìŠ¤íŠ¸ DB)
  - [ ] ê° í…ŒìŠ¤íŠ¸ê°€ ì‹¤ì œ Agent í˜¸ì¶œ (Mock ì œì™¸)
  - [ ] API ì‘ë‹µ í¬ë§· ê²€ì¦
  - [ ] DB ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
  - [ ] ì—ëŸ¬ ì¼€ì´ìŠ¤ í¬í•¨
  - [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œê°„ < 5ë¶„
  - [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ (tox -e py311)

Priority: ğŸŸ¡ MEDIUM
Dependencies: [REQ-A-Agent-Backend-1, REQ-A-Agent-Backend-2]
Status: â³ Backlog
```

---

## Phaseë³„ ì„¸ë¶€ ê³„íš

### Phase 0ï¸âƒ£: Agent ê¸°ë³¸ ë™ì‘ í™•ì¸ (REQ-A-Agent-Sanity-0)

**ì¤€ë¹„ ì‘ì—…**:

```bash
# 1. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export GEMINI_API_KEY="your_actual_key"
export LANGCHAIN_DEBUG=1  # ë˜ëŠ” LANGCHAIN_TRACING_V2=1

# 2. í”„ë¡œì íŠ¸ ì¤€ë¹„
uv sync
```

**êµ¬í˜„ (30ë¶„)**:

1. `scripts/test_agent_sanity_check.py` ìƒì„±
   - `create_agent()` í˜¸ì¶œ
   - `GenerateQuestionsRequest` ìƒì„±
   - `agent.generate_questions()` ì‹¤í–‰
   - JSON ì¶œë ¥

2. ì‹¤í–‰:

   ```bash
   uv run python scripts/test_agent_sanity_check.py
   ```

3. ê²€ì¦:
   - ë¡œê·¸ ì¶œë ¥ í™•ì¸
   - Tool í˜¸ì¶œ ì¶”ì  (Tool 1, 3, 5)
   - ìµœì¢… ì¶œë ¥ JSON í¬ë§·

**ì‚°ì¶œë¬¼**:

- `scripts/test_agent_sanity_check.py`
- `docs/progress/REQ-A-Agent-Sanity-0.md` (Phase 1-4 ë¬¸ì„œ)

---

### Phase 1ï¸âƒ£: CLI ëª…ë ¹ì–´ í™•ì¥ (REQ-CLI-Agent-1, 2, 3)

**íŒŒì¼ êµ¬ì¡°**:

```
src/cli/
â”œâ”€â”€ main.py                    â† ìˆ˜ì •: agent ëª…ë ¹ ë“±ë¡
â””â”€â”€ actions/
    â””â”€â”€ [NEW] agent.py         â† ìƒì„±: agent ëª…ë ¹ êµ¬í˜„
```

**Task 1-1: CLI êµ¬ì¡° íŒŒì•… (10ë¶„)**

- `src/cli/main.py` ì½ê¸° (ëª…ë ¹ ê·¸ë£¹ êµ¬ì¡°)
- `src/cli/actions/questions.py` ì°¸ê³  (êµ¬í˜„ íŒ¨í„´)
- `run.py` í™•ì¸ (ì§„ì…ì )

**Task 1-2: agent.py êµ¬í˜„ (30ë¶„)**

```python
# src/cli/actions/agent.py

async def generate_questions(survey_id, round_idx, prev_answers):
    """Agent í˜¸ì¶œ ë° ê²°ê³¼ ì¶œë ¥"""
    agent = await create_agent()
    request = GenerateQuestionsRequest(...)
    response = await agent.generate_questions(request)
    _display_response(response)

async def score_answer(round_id, item_id, user_answer, ...):
    """Tool 6 í˜¸ì¶œ ë° ì±„ì  ê²°ê³¼ ì¶œë ¥"""
    agent = await create_agent()
    request = ScoreAnswerRequest(...)
    response = await agent.score_and_explain(request)
    _display_score(response)
```

**Task 1-3: main.py ìˆ˜ì • (10ë¶„)**

```python
from src.cli.actions import agent

@main.group()
def agent_cmd():
    """Agent-based operations"""
    pass

@agent_cmd.command()
@click.option("--survey-id", required=True)
@click.option("--round", default=1, type=int)
def generate_questions(survey_id, round):
    asyncio.run(agent.generate_questions(survey_id, round))

main.add_command(agent_cmd, name="agent")
```

**Task 1-4: í…ŒìŠ¤íŠ¸ (10ë¶„)**

```bash
./tools/dev.sh cli agent --help
./tools/dev.sh cli agent generate-questions --survey-id "test_001" --round 1
./tools/dev.sh cli agent score-answer --round-id "r1" --item-id "q1" --user-answer "test"
```

**ì‚°ì¶œë¬¼**:

- `src/cli/actions/agent.py`
- `src/cli/main.py` ìˆ˜ì •
- `docs/progress/REQ-CLI-Agent-{1,2,3}.md` (ê°ê° Phase 1-4 ë¬¸ì„œ)

---

### Phase 2ï¸âƒ£: FastAPI ë°±ì—”ë“œ í†µí•© (REQ-A-Agent-Backend-1, 2)

**Task 2-1: QuestionGenerationService ìˆ˜ì • (1ì‹œê°„)**

**íŒŒì¼**: `src/backend/services/question_gen_service.py`

**ì£¼ìš” ë³€ê²½**:

```python
# Before (í˜„ì¬ - Mock)
class QuestionGenerationService:
    def generate_questions(self, survey_id: str, round_num: int) -> dict:
        return MOCK_QUESTIONS

# After (ë³€ê²½ í›„ - Agent)
class QuestionGenerationService:
    async def generate_questions(self, survey_id: str, round_num: int) -> dict:
        # 1. Agent ìƒì„±
        agent = await create_agent()

        # 2. ìš”ì²­ ìƒì„± (ì´ì „ ë‹µë³€ í¬í•¨)
        prev_answers = self._get_previous_answers(survey_id, round_num - 1)
        request = GenerateQuestionsRequest(
            survey_id=survey_id,
            round_idx=round_num,
            prev_answers=prev_answers,
        )

        # 3. Agent í˜¸ì¶œ
        response = await agent.generate_questions(request)

        # 4. DB ì €ì¥
        session = self._create_test_session(survey_id, round_num)
        questions = self._save_questions_to_db(session, response.items)

        # 5. ì‘ë‹µ ë°˜í™˜
        return {
            "session_id": session.id,
            "questions": [self._format_q(q) for q in questions],
            "time_limit_seconds": response.time_limit_seconds,
            "agent_steps": response.agent_steps,
        }
```

**ì¶”ê°€ ë©”ì„œë“œ**:

```python
def _get_previous_answers(self, survey_id: str, prev_round: int) -> list[dict]:
    """ì´ì „ ë¼ìš´ë“œ ë‹µë³€ ì¡°íšŒ"""
    # DBì—ì„œ previous_roundì˜ test_responses ì¡°íšŒ
    # Return: [{"item_id": "q1", "score": 85}, ...]

def _create_test_session(self, survey_id: str, round_num: int) -> TestSession:
    """ìƒˆ TestSession ìƒì„±"""
    # TestSession ORM ê°ì²´ ìƒì„± ë° ì €ì¥

def _save_questions_to_db(self, session, items) -> list[Question]:
    """ìƒì„±ëœ ë¬¸í•­ì„ Question í…Œì´ë¸”ì— ì €ì¥"""
    # GeneratedItem â†’ Question ORM ë³€í™˜
    # DB ì €ì¥

def _format_question(self, q: Question) -> dict:
    """Question ORM â†’ API ì‘ë‹µ í¬ë§·"""
    return {
        "id": q.id,
        "item_type": q.item_type,
        "stem": q.stem,
        "choices": q.choices,
        "answer_schema": {...},
        "difficulty": q.difficulty,
        "category": q.category,
    }
```

**Task 2-2: API ì—”ë“œí¬ì¸íŠ¸ ê²€ì¦ (15ë¶„)**

**íŒŒì¼**: `src/backend/api/questions.py`

```python
@router.post("/generate")
async def generate_questions(
    request: GenerateQuestionsRequest,
    db: Session = Depends(get_db),
) -> GenerateQuestionsResponse:
    """Generate questions using Agent"""
    service = QuestionGenerationService(db)
    result = await service.generate_questions(
        request.survey_id,
        request.round
    )
    return GenerateQuestionsResponse(**result)
```

**Task 2-3: ScoringService ìˆ˜ì • (ì„ íƒì‚¬í•­, 1ì‹œê°„)**

**íŒŒì¼**: `src/backend/services/scoring_service.py`

```python
async def score_answer(
    self,
    session_id: str,
    question_id: str,
    user_answer: str,
    response_time_ms: int = 0,
) -> dict:
    """Score answer using Agent Tool 6"""
    agent = await create_agent()

    # ì§ˆë¬¸ ì •ë³´ ì¡°íšŒ
    question = self.db.query(Question).filter_by(id=question_id).first()
    if not question:
        raise ValueError(f"Question {question_id} not found")

    # ì±„ì  ìš”ì²­
    request = ScoreAnswerRequest(
        round_id=session_id,
        item_id=question_id,
        user_answer=user_answer,
        question_type=question.item_type,
        correct_answer=question.correct_answer,
        correct_keywords=question.correct_keywords,
        difficulty=question.difficulty,
        category=question.category,
        response_time_ms=response_time_ms,
    )

    # Agent í˜¸ì¶œ
    response = await agent.score_and_explain(request)

    # DB ì €ì¥
    self._save_attempt_answer(session_id, question_id, user_answer, response)

    return response.model_dump()

async def submit_answers(
    self,
    session_id: str,
    answers: list[tuple[str, str]],  # (question_id, user_answer)
) -> dict:
    """Batch scoring using Tool 6 (parallel)"""
    # ì—¬ëŸ¬ ë‹µë³€ì„ ë³‘ë ¬ë¡œ ì±„ì 
    # Return: batch results + round statistics
```

**Task 2-4: ìœ ë‹› í…ŒìŠ¤íŠ¸ ì‘ì„± (1ì‹œê°„)**

**íŒŒì¼**: `tests/backend/test_question_gen_service_agent.py`

```python
@pytest.mark.asyncio
async def test_generate_questions_calls_agent(db_session):
    """QuestionGenerationServiceê°€ Agentë¥¼ í˜¸ì¶œí•˜ëŠ”ì§€ í™•ì¸"""
    service = QuestionGenerationService(db_session)

    with patch("src.backend.services.question_gen_service.create_agent") as mock_create:
        mock_agent = AsyncMock()
        mock_create.return_value = mock_agent

        mock_agent.generate_questions.return_value = GenerateQuestionsResponse(
            round_id="r123",
            items=[...],  # 3ê°œ ë¬¸í•­
            time_limit_seconds=1200,
        )

        result = await service.generate_questions("survey_123", 1)

        # Assertions
        mock_agent.generate_questions.assert_called_once()
        assert len(result["questions"]) == 3
        assert "session_id" in result

@pytest.mark.asyncio
async def test_generate_questions_saves_to_db(db_session):
    """ìƒì„±ëœ ë¬¸í•­ì´ DBì— ì €ì¥ë˜ëŠ”ì§€ í™•ì¸"""
    # ... Agent í˜¸ì¶œ í›„ DBì— Question ë ˆì½”ë“œ í™•ì¸
```

**ì‚°ì¶œë¬¼**:

- `src/backend/services/question_gen_service.py` ìˆ˜ì •
- `src/backend/services/scoring_service.py` ìˆ˜ì • (ì„ íƒì‚¬í•­)
- `src/backend/api/questions.py` ê²€ì¦
- `tests/backend/test_question_gen_service_agent.py` ìƒì„±
- `docs/progress/REQ-A-Agent-Backend-{1,2}.md` (Phase 1-4 ë¬¸ì„œ)

---

### Phase 3ï¸âƒ£: E2E í†µí•© í…ŒìŠ¤íŠ¸ (REQ-A-Agent-Integration-1)

**Task 3-1: í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‘ì„± (1.5ì‹œê°„)**

**íŒŒì¼**: `tests/integration/test_agent_backend_e2e.py`

```python
import pytest
from httpx import AsyncClient
from src.backend.main import app
from src.agent.llm_agent import GenerateQuestionsRequest

class TestAgentBackendIntegration:
    """E2E integration tests: CLI â†’ API â†’ Agent â†’ DB"""

    @pytest.mark.asyncio
    async def test_generate_questions_e2e(self, client: AsyncClient, db_session):
        """API â†’ Service â†’ Agent â†’ DB ì „ì²´ íë¦„"""
        # 1. Survey ìƒì„±
        # 2. POST /questions/generate
        # 3. ì‘ë‹µ ê²€ì¦
        # 4. DB ê²€ì¦
        pass

    @pytest.mark.asyncio
    async def test_score_answer_e2e(self, client: AsyncClient, db_session):
        """ë‹¨ì¼ ë‹µë³€ ì±„ì """
        pass

    @pytest.mark.asyncio
    async def test_batch_scoring_e2e(self, client: AsyncClient, db_session):
        """ë°°ì¹˜ ì±„ì """
        pass

    @pytest.mark.asyncio
    async def test_adaptive_questioning_e2e(self, client: AsyncClient, db_session):
        """Round 1 â†’ Round 2 (ì ì‘í˜•)"""
        pass
```

**Task 3-2: CLI ê¸°ë°˜ E2E í…ŒìŠ¤íŠ¸ (30ë¶„)**

**íŒŒì¼**: `scripts/test_e2e_cli.sh`

```bash
#!/bin/bash
set -e

echo "ğŸš€ E2E Test: Agent Integration"

# 1. ì„œë²„ ì‹œì‘
./tools/dev.sh up &
SERVER_PID=$!
sleep 3

# 2. ë¬¸í•­ ìƒì„±
./tools/dev.sh cli agent generate-questions \
  --survey-id "e2e_test_$(date +%s)" \
  --round 1

# 3. ë‹µë³€ ì±„ì 
./tools/dev.sh cli agent score-answer \
  --round-id "test_round" \
  --item-id "test_item" \
  --user-answer "test answer"

# 4. ì •ë¦¬
kill $SERVER_PID
echo "âœ… E2E Test Complete"
```

**Task 3-3: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê²€ì¦ (30ë¶„)**

```bash
# í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/integration/test_agent_backend_e2e.py -v

# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
tox -e py311

# í¬ë§· ê²€ì‚¬
./tools/dev.sh format
```

**ì‚°ì¶œë¬¼**:

- `tests/integration/test_agent_backend_e2e.py`
- `scripts/test_e2e_cli.sh`
- `docs/progress/REQ-A-Agent-Integration-1.md` (Phase 1-4 ë¬¸ì„œ)

---

## íƒ€ì„ë¼ì¸ & ì§„í–‰ ì¶”ì 

### ì˜ˆìƒ ì†Œìš” ì‹œê°„

| Phase | REQ ID | ì†Œìš”ì‹œê°„ | ë‚œì´ë„ | ìƒíƒœ |
|-------|--------|---------|--------|------|
| **0** | REQ-A-Agent-Sanity-0 | 30ë¶„ | â­ | â³ Backlog |
| **1** | REQ-CLI-Agent-1 | 20ë¶„ | â­ | â³ Backlog |
| **1** | REQ-CLI-Agent-2 | 40ë¶„ | â­â­ | â³ Backlog |
| **1** | REQ-CLI-Agent-3 | 30ë¶„ | â­â­ | â³ Backlog |
| **1** | REQ-CLI-Agent-4 | 30ë¶„ | â­â­ | â³ Backlog |
| **1** | REQ-CLI-Agent-5 | 1ì‹œê°„ | â­â­â­ | â³ Backlog |
| **2** | REQ-A-Agent-Backend-1 | 1ì‹œê°„ 30ë¶„ | â­â­â­ | â³ Backlog |
| **2** | REQ-A-Agent-Backend-2 | 1ì‹œê°„ (ì„ íƒ) | â­â­â­ | â³ Backlog |
| **3** | REQ-A-Agent-Integration-1 | 2ì‹œê°„ | â­â­ | â³ Backlog |
| | **ì´ê³„** | **ì•½ 8ì‹œê°„** | | |

### ì§„í–‰ ì¶”ì  ë°©ë²•

ê° REQ ì™„ë£Œ í›„:

1. **ì§„í–‰ íŒŒì¼ ìƒì„±**: `docs/progress/REQ-[ID].md`

   ```markdown
   # REQ-A-Agent-Sanity-0: Agent ê¸°ë³¸ ë™ì‘ ê²€ì¦

   ## Phase 1: ëª…ì„¸ (Specification)
   [ìë™ ìƒì„±, ì´ ë¬¸ì„œì—ì„œ ë³µì‚¬]

   ## Phase 2: í…ŒìŠ¤íŠ¸ ì„¤ê³„
   [í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë‚˜ì—´]

   ## Phase 3: êµ¬í˜„
   - [ ] íŒŒì¼ ìƒì„±/ìˆ˜ì •
   - [ ] í…ŒìŠ¤íŠ¸ í†µê³¼
   - [ ] í¬ë§· ê²€ì‚¬

   ## Phase 4: ìš”ì•½
   - Modified: scripts/test_agent_sanity_check.py
   - Tests: âœ… PASS
   - Commit: abc123def456
   ```

2. **Progress íŒŒì¼ ì—…ë°ì´íŠ¸**: `docs/DEV-PROGRESS.md`

   ```markdown
   | REQ-A-Agent-Sanity-0 | 4 | âœ… Done | Commit: abc123 |
   ```

3. **Git Commit**:

   ```bash
   git add docs/progress/REQ-A-Agent-Sanity-0.md docs/DEV-PROGRESS.md
   git commit -m "feat: REQ-A-Agent-Sanity-0 - Agent ê¸°ë³¸ ë™ì‘ ê²€ì¦

   - ì‹¤ì œ Google Gemini LLM ì—°ê²° ê²€ì¦
   - LANGCHAIN_DEBUGë¡œ Tool í˜¸ì¶œ ì¶”ì 
   - ë¬¸í•­ 3ê°œ ì´ìƒ ìƒì„± í™•ì¸

   ğŸ¤– Generated with Claude Code"
   ```

---

## ë‹¤ìŒ ë‹¨ê³„: ì‹œì‘í•˜ê¸°

**ì¤€ë¹„**:

1. ì´ ë¬¸ì„œ ê²€í†  (ì§€ê¸ˆ)
2. ë™ë£Œ ì˜ê²¬ í†µí•© ì™„ë£Œ âœ…
3. REQ ID ì²´ê³„ í™•ì • âœ…

**ê°œë°œ ì‹œì‘**:

### Option A: Phase 0ë¶€í„° ìˆœì°¨ ì§„í–‰ (ì¶”ì²œ)

```bash
# Phase 0
uv run python scripts/test_agent_sanity_check.py

# Phase 1
./tools/dev.sh cli agent --help

# Phase 2
pytest tests/backend/test_question_gen_service_agent.py

# Phase 3
pytest tests/integration/test_agent_backend_e2e.py
```

### Option B: ë³‘ë ¬ ì§„í–‰ (ë¹ ë¦„)

- Phase 0, 1, 2ë¥¼ ë™ì‹œì— ì§„í–‰
- ì•½ 3-4ì‹œê°„ ì†Œìš”

---

## ì°¸ê³  ìë£Œ

### ê¸°ì¡´ ì½”ë“œ ì°¸ê³ 

- Agent êµ¬í˜„: `src/agent/llm_agent.py` (910ì¤„)
- Agent í…ŒìŠ¤íŠ¸: `tests/agent/test_llm_agent.py` (1290ì¤„)
- CLI êµ¬ì¡°: `src/cli/main.py`, `src/cli/actions/`
- BackEnd ì„œë¹„ìŠ¤: `src/backend/services/`

### ë¬¸ì„œ

- CLAUDE.md: REQ-Based Workflow ì •ì˜
- CLAUDE.md Â§ CLI Feature Requirement Workflow

### ë™ë£Œ ì˜ê²¬ ì›ë¬¸

- ë™ë£Œ A: CLI êµ¬ì¡° í™•ì¥ (Task 1-1, 1-2, 1-3)
- ë™ë£Œ B: Agent ê²€ì¦ ìš°ì„  (Phase 0, LANGCHAIN_DEBUG)

---

**ì‘ì„±ì**: Claude Code
**ë§ˆì§€ë§‰ ìˆ˜ì •**: 2025-11-11
**ìƒíƒœ**: ğŸ‘¨â€ğŸ’¼ ê²€í†  ëŒ€ê¸° (ìŠ¹ì¸ í›„ Phase 0 ì‹œì‘ ê¶Œì¥)
