# User Scenarios - MVP 1.0 & 2.0 정의

## 📋 목차

- [MVP 1.0 시나리오](#mvp-10-시나리오)
  - [시나리오 0: 사용자 가입](#시나리오-0-사용자-가입)
  - [시나리오 1: AI 역량 레벨 테스트](#시나리오-1-ai-역량-레벨-테스트)
  - [시나리오 1-4: 재미 모드 (카테고리 선택형 퀴즈)](#시나리오-1-4-재미-모드-카테고리-선택형-퀴즈)
  - [시나리오 1-5: 학습 일정 예고 (MVP 2.0 프리뷰)](#시나리오-1-5-학습-일정-예고-mvp-20-프리뷰)
- [MVP 2.0 시나리오](#mvp-20-시나리오)
  - [시나리오 1-6: RAG 기반 동적 문제 생성 (MVP 2.0 강화)](#시나리오-1-6-rag-기반-동적-문제-생성-mvp-20-강화)
  - [시나리오 2: 학습 아이템 등록](#시나리오-2-학습-아이템-등록)
  - [시나리오 3: 학습 아이템 평가](#시나리오-3-학습-아이템-평가)
  - [시나리오 4: 학습 아이템 검색](#시나리오-4-학습-아이템-검색)
- [AI Agent 아키텍처](#ai-agent-아키텍처)
- [공통 원칙 및 설계 철학](#공통-원칙-및-설계-철학)

---

# MVP 1.0 시나리오

## 시나리오 0: 사용자 가입

### BDD: User Story & Acceptance Criteria

- **As a** 사내 임직원
- **I want to** 처음 시스템에 접속할 때 AD 계정으로 로그인하고 닉네임을 설정하여 가입을 완료한다.
- **So that** 'slea-ssem' 서비스를 이용할 수 있는 기본 자격을 얻는다.

#### ✅ Acceptance Criteria

1. 사용자가 웹 시스템에 접속하면 **AD 로그인 페이지**로 연결되어야 한다.
2. **AD 인증 실패 시** 재시도 안내 및 헬프 링크를 제공해야 한다.
3. AD 인증에 성공한 **최초 사용자**는 자동으로 가입 안내 페이지로 리다이렉트되어야 한다.
4. **기존 가입 사용자**는 AD 인증 후 즉시 메인 대시보드(테스트 또는 홈)로 이동해야 한다.
5. 닉네임 입력 시 **실시간 중복 확인** 기능을 제공해야 한다.
6. **닉네임 중복 감지 시** 유사 추천 닉네임 3개를 자동 제안해야 한다.
7. 가입 완료 시 사용자 정보(AD 계정, 닉네임, 부서, 생성일)가 DB에 저장되어야 한다.
8. 세션이 유지되어야 하고, 온보딩 모달에서 "테스트 시작" CTA를 제공해야 한다.

---

### Scenario 0-1: 신입 임직원의 첫 가입 - Happy Path

**사용자 프로필**

- 이름: 김태호 (입사 1개월 차 신입)
- 직책: 엔지니어
- AD 계정: <kim.taeho@company.com>

**상황**

- 입사 오리엔테이션에서 학습 플랫폼 안내를 받음
- 웹사이트 링크를 클릭하여 첫 접속

**흐름**

| 단계 | 액션 | 시스템 응답 | 사용자 상태 |
|------|------|----------|----------|
| 1 | 웹사이트 접속 (unauthenticated) | 로그인 페이지 노출, "AD 로그인" 버튼 표시 | 초기 상태 |
| 2 | AD 로그인 클릭 | Samsung AD 로그인 페이지로 리다이렉트 | 인증 중 |
| 3 | 회사 AD 계정으로 로그인 (<kim.taeho@company.com> / 암호) | AD 인증 성공 → 시스템으로 콜백 (JWT 토큰 발급) | 인증됨 |
| 4 | 시스템 리다이렉트 | 가입 안내 페이지 노출: "환영합니다! 학습 플랫폼 가입을 시작하겠습니다" | 가입 안내 화면 |
| 5 | 닉네임 입력 필드에 "태호" 입력 | 입력 필드 활성화 상태 | 닉네임 입력 중 |
| 6 | "중복 확인" 버튼 클릭 | 백엔드 검증: 닉네임 "태호"는 사용 가능 → "사용 가능한 닉네임입니다" 메시지 | 중복 검증 완료 |
| 7 | "가입 완료" 버튼 클릭 | DB에 사용자 정보 저장: (ad_id, email, nickname, created_at, status='active') → 가입 완료 페이지 리다이렉트 | 가입 완료 |
| 8 | 가입 완료 페이지 노출 | "가입이 완료되었습니다! 이제 레벨 테스트를 시작할 수 있습니다" 메시지 + "테스트 시작" CTA 버튼 | 온보딩 완료 |

**예상 결과**

- ✅ users 테이블에 신규 레코드 생성
- ✅ 사용자 세션 상태 = 'registered'
- ✅ 다음 단계: 시나리오 1 (레벨 테스트)로 진행 가능

**검증 포인트**

- AD 계정 정보와 nickname이 정확히 매핑되었는가?
- 중복 닉네임 검증 로직이 정상 작동하는가?
- DB 트랜잭션이 atomic하게 처리되었는가?

---

### Scenario 0-2: 기존 임직원의 닉네임 재설정 시나리오

**사용자 프로필**

- 이름: 이민준 (재직 3년 차)
- 직책: 시니어 엔지니어
- AD 계정: <min.jun.lee@company.com>

**상황**

- 2주 전에 한 번 가입했으나, 닉네임을 "min_jun"으로 너무 딱딱하게 설정함
- 재로그인 후 닉네임을 친근하게 변경하고 싶음

**흐름**

| 단계 | 액션 | 시스템 응답 | 사용자 상태 |
|------|------|----------|----------|
| 1 | 웹사이트 재접속 | 로그인 페이지 노출 | 초기 상태 |
| 2 | AD 로그인 | AD 인증 성공 (JWT 토큰 재발급) | 인증됨 |
| 3 | 시스템 리다이렉트 | 기존 가입 사용자 감지 → 메인 대시보드로 이동 (가입 페이지 스킵) | 대시보드 진입 |
| 4 | 사용자 프로필 메뉴 클릭 | 프로필 수정 페이지 노출: 현재 닉네임 "min_jun" 표시, 수정 옵션 제공 | 프로필 페이지 |
| 5 | 닉네임 필드 클릭 → "민준" 입력 | 입력 필드 활성화 | 닉네임 변경 중 |
| 6 | "중복 확인" 버튼 클릭 | 검증: "민준"은 새로운 닉네임, 사용 가능 → "사용 가능합니다" | 중복 검증 완료 |
| 7 | "저장" 버튼 클릭 | DB 업데이트: users.nickname = "민준", updated_at 갱신 → "저장되었습니다" 메시지 | 변경 저장 |
| 8 | 페이지 새로고침 | 대시보드에 "민준" 닉네임 표시 | 변경 반영됨 |

**예상 결과**

- ✅ 기존 사용자 감지 로직 정상 작동
- ✅ 닉네임 변경 시 중복 검증 (기존 닉네임 "min_jun"과 충돌 무시)
- ✅ DB 업데이트 로직 정상 작동

**검증 포인트**

- 기존 사용자 재방문 시 가입 안내 페이지를 건너뛰는가?
- 닉네임 변경 시 `updated_at` 타임스탬프가 갱신되는가?
- 닉네임 중복 검증 시 자신의 기존 닉네임은 제외하는가?

---

### Scenario 0-3: 닉네임 중복 충돌 시나리오

**사용자 프로필**

- 이름: 박서연 (입사 6개월 차)
- 직책: 주니어 엔지니어
- AD 계정: <seo.yeon.park@company.com>

**상황**

- 첫 가입 진행 중
- "서연"이라는 닉네임을 입력했으나, 이미 다른 임직원이 사용 중
- 사용자가 닉네임을 변경하여 다시 시도

**흐름**

| 단계 | 액션 | 시스템 응답 | 사용자 상태 |
|------|------|----------|----------|
| 1 | AD 로그인 성공 | 가입 안내 페이지 노출 | 가입 진행 중 |
| 2 | 닉네임 입력 필드에 "서연" 입력 | 입력 필드 활성화 | 닉네임 입력 |
| 3 | "중복 확인" 버튼 클릭 | DB 쿼리: SELECT COUNT(*) FROM users WHERE nickname='서연' → count = 1 (이미 사용 중) → 에러 메시지 표시: "이미 사용 중인 닉네임입니다. 다른 닉네임을 입력해주세요" | 중복 감지 |
| 4 | 닉네임 필드 초기화 후 "seo_yeon" 입력 | 입력 필드 리셋, 새로운 값 입력 | 닉네임 재입력 |
| 5 | "중복 확인" 버튼 클릭 | DB 검증: "seo_yeon" 사용 가능 → "사용 가능한 닉네임입니다" 표시 | 중복 검증 성공 |
| 6 | "가입 완료" 버튼 클릭 | DB 저장: (ad_id='<seo.yeon.park@company.com>', nickname='seo_yeon', created_at=NOW()) | 가입 완료 |
| 7 | 가입 완료 페이지 리다이렉트 | "가입이 완료되었습니다" 메시지 + "테스트 시작" CTA | 온보딩 완료 |

**예상 결과**

- ✅ 중복 닉네임 감지 및 에러 메시지 표시
- ✅ 사용자가 닉네임 변경 후 재검증 가능
- ✅ 최종적으로 "seo_yeon" 닉네임으로 가입 완료

**검증 포인트**

- 닉네임 중복 감지 로직이 case-insensitive인가? 또는 case-sensitive인가? (정책 정의 필요)
- 중복 검증 후 입력 필드가 여전히 활성 상태인가?
- 에러 메시지가 명확하고 다음 액션을 안내하는가?
- DB 동시성 제어: 두 사용자가 동시에 같은 닉네임으로 등록하려 할 때 UNIQUE 제약 조건 작동하는가?

---

## 시나리오 1: AI 역량 레벨 테스트

### BDD: User Story & Acceptance Criteria

- **As a** 가입한 임직원
- **I want to** 내 경력, 직군, 관심사에 맞춰진 **2단계 적응형 AI 역량 테스트**를 수행하고 최종 등급을 받는다.
- **So that** 나의 AI 지식 수준을 객관적인 등급(5단계)과 상세 해설로 파악하고, 향후 학습 계획 수립의 기초를 마련한다.

#### ✅ Acceptance Criteria

1. 사용자는 테스트 시작 전 **자기평가 폼**을 제출해야 한다:
   - 자신이 생각하는 수준(초급/중급/상급)
   - 경력(연차): 숫자 입력
   - 직군 선택(백엔드, 프론트엔드, DevOps, 데이터 등)
   - 담당 업무: 텍스트 입력
   - 관심분야: 체크박스 다중 선택(LLM, RAG, Agent Architecture, Prompt Engineering, Deep Learning 등)

2. 시스템은 입력된 정보를 바탕으로 **1차 문제 세트(5문제)**를 동적으로 생성해야 한다:
   - LLM이 선택된 관심분야와 난이도를 기반으로 문제 생성
   - 선택된 난이도 반영
   - 선택된 관심분야 포함
   - 문제 타입: 객관식/OX/주관식 혼합

3. 사용자가 1차 문제 풀이를 완료하면, **자동 채점**이 즉시 수행되어야 한다:
   - 객관식/OX: 정답 일치 판정
   - 주관식: LLM 기반 채점(부분점수 포함)

4. 1차 점수에 따라 **적응형 난이도 조정**이 수행되어야 한다:
   - 점수 0-40: 난이도 유지 또는 감소
   - 점수 40-70: 난이도 유지 또는 약간 증가
   - 점수 70+: 난이도 상향 또는 초상급 활성화

5. 시스템은 2차 문제 세트(5문제)를 **1차 오답 분야 강화**하여 생성해야 한다.

6. 사용자가 2차 문제를 완료하면 **최종 평가**가 실행되어야 한다:
   - 종합 점수 산출(1차, 2차 점수 가중치 계산)
   - **5등급 체계** 산출: Beginner, Intermediate, Intermediate-Advanced, Advanced, Elite
   - 전사 상대 순위 계산(예: 145/506)
   - 상위 백분위 계산(예: 상위 28%)

7. 결과 페이지에는 다음 정보가 표시되어야 한다:
   - 최종 등급 + 5등급 설명
   - 총합 점수 및 분야별 점수 분석
   - 각 문제의 정답, 사용자 답변, 해설
   - 전사 상대 순위 및 분포
   - **공유용 이미지/배지** (사내 피드 공유용)

8. 테스트 진행 중 사용자의 응답은 **실시간 자동 저장**되어야 한다.

9. 20분 제한 초과 시 **진행상태 저장** 후 재개 안내를 제공해야 한다.

10. 사용자는 언제든 **레벨 테스트를 반복 응시**할 수 있고, 이전 응시 이력이 저장되어야 한다.

11. (선택) **카테고리별 추가 문제**: 마케팅, 반도체, 센서, RTL 등 "재미" 요소로 추가 가능.

---

### Scenario 1-1: 신입 엔지니어의 첫 레벨 테스트 - 2단계 적응형 진행

**사용자 프로필**

- 이름: 김태호 (시나리오 0-1과 동일)
- 닉네임: "태호"
- 현재 상태: 가입 완료 (status='registered')
- 배경: 신입, 개발 경험 3년 정도

**상황**

- 가입 완료 후 "테스트 시작" 버튼 클릭
- 사용자 정보 입력 페이지 노출

**흐름**

| 단계 | 액션 | 시스템 응답 | 사용자 상태 |
|------|------|----------|----------|
| 1 | "테스트 시작" 클릭 | 사용자 정보 입력 페이지 노출 | 테스트 사전 정보 수집 중 |
| 2 | 자신이 생각하는 수준 선택: "초급" | 드롭다운 메뉴에서 선택 (초급/중급/상급) | 수준 선택 완료 |
| 3 | 경력(연차) 입력: "3년" | 입력 필드에 숫자 입력 | 경력 입력 완료 |
| 4 | 직군 선택: "백엔드 개발자" | 다중 선택 옵션 (백엔드, 프론트엔드, DevOps, 데이터 등) | 직군 선택 완료 |
| 5 | 담당 업무 입력: "FastAPI를 이용한 API 개발" | 텍스트 입력 필드 | 담당 업무 입력 완료 |
| 6 | 관심분야 선택: ["LLM", "RAG"] | 체크박스 다중 선택 | 관심분야 선택 완료 |
| 7 | "다음" 버튼 클릭 | 백엔드에서 사용자 프로필 저장 (users_profile 테이블) + 1차 테스트 문제 생성 (LLM 기반, 초급 레벨, 5개 문제) | 1차 테스트 시작 준비 |
| 8 | 1차 테스트 페이지 로드 | 5개 문제 노출 (객관식, 주관식 혼합) 타이머: 20분 | 1차 테스트 진행 중 |
| 9 | 문제 1~5 풀이 | 각 문제에 답변 입력 (진행 상황 실시간 저장) | 테스트 진행 중 |
| 10 | "제출" 버튼 클릭 | 1차 응답 데이터 DB 저장 + 자동 채점 (스코어 계산) + 2차 테스트 문제 생성 (1차 점수 기반 난이도 조정) | 1차 완료, 2차 준비 |
| 11 | 2차 테스트 페이지 로드 | 5개 문제 노출 (중급 난이도로 상향 조정, 1차 오답 분야 강화) | 2차 테스트 진행 중 |
| 12 | 문제 1~5 풀이 | 답변 입력 | 테스트 진행 중 |
| 13 | "제출" 버튼 클릭 | 2차 응답 DB 저장 + 자동 채점 + 최종 평가 로직 실행 | 테스트 완료 |
| 14 | 최종 결과 페이지 노출 | **결과 요약:** 등급 "중급", 총점 72/100, 분야별 점수 (LLM: 80%, RAG: 65%), 순위 (전사 기준 145/506, 상위 28%) | 결과 확인 중 |
| 15 | 결과 페이지 스크롤 | 풀이 내용 제시 (각 문제의 정답, 사용자 답변, 해설) + 등급 설명 ("중급: 업계 경험 3~5년 수준") | 결과 상세 확인 |
| 16 | "대시보드로 이동" 클릭 | 사용자 메인 대시보드 → 테스트 결과 카드 표시, "재응시" 옵션 제공 | 테스트 완료, 대시보드 진입 |

**예상 결과**

- ✅ users_profile 테이블에 사용자 프로필 정보 저장
- ✅ test_sessions 테이블에 테스트 세션 생성 (session_id, user_id, created_at)
- ✅ test_responses 테이블에 각 문제별 응답 저장
- ✅ test_results 테이블에 최종 결과 저장 (grade='intermediate', score=72, rank=145)
- ✅ 적응형 알고리즘: 1차 점수에 따라 2차 난이도 자동 조정
- ✅ 사용자에게 등급, 점수, 순위, 해설 제시

**검증 포인트**

- 사용자 정보 입력 유효성 검증 (필수 필드, 형식 검증)
- LLM 기반 동적 문제 생성이 정상 작동하는가?
- 자동 채점 로직이 정확한가?
- 적응형 난이도 조정 알고리즘이 의도대로 작동하는가?
- 순위 계산이 정확한가? (동일 점수 시 처리)
- 세션 타임아웃 처리는 어떻게 하는가? (문제 풀이 중 20분 초과 시)

---

### Scenario 1-2: 기존 사용자의 2회차 레벨 테스트 재응시

**사용자 프로필**

- 이름: 이민준 (시나리오 0-2와 동일)
- 닉네임: "민준"
- 현재 상태: 1회차 테스트 완료 (grade='intermediate', score=72)
- 배경: 3년 차 시니어 엔지니어

**상황**

- 1주일 전 첫 테스트 응시 후 학습 진행
- 오늘 재응시하여 등급 상향 시도

**흐름**

| 단계 | 액션 | 시스템 응답 | 사용자 상태 |
|------|------|----------|----------|
| 1 | 대시보드에서 "레벨 테스트 재응시" 버튼 클릭 | 사용자 정보 입력 페이지 노출 (이전 정보 자동 로드) | 재응시 준비 중 |
| 2 | 자신이 생각하는 수준: "중급" (이전 "중급"에서 유지) | 드롭다운 메뉴 수정 (선택 사항) | 수준 확인 |
| 3 | 관심분야 추가: ["LLM", "RAG", "Deep Learning"] (새로 "Deep Learning" 추가) | 체크박스 다중 선택 업데이트 | 관심분야 확대 |
| 4 | "다음" 버튼 클릭 | 백엔드: 이전 프로필 업데이트 + 1차 테스트 문제 생성 (사용자의 이전 점수 72점 기준 중상급 난이도로 출제) | 1차 테스트 시작 준비 |
| 5 | 1차 테스트 페이지 로드 | 5개 문제 노출 (중상급 난이도, 이번엔 Deep Learning 분야 강화) | 1차 테스트 진행 중 |
| 6 | 문제 풀이 진행 중 | 진행 상황 실시간 저장 (예: 3번 문제까지 완료 후 임시 저장) | 테스트 진행 중 |
| 7 | "제출" 버튼 클릭 | 1차 응답 저장 + 자동 채점 (이번엔 82점 획득) + 2차 테스트 생성 (난이도 상향) | 1차 완료 |
| 8 | 2차 테스트 페이지 로드 | 5개 문제 노출 (상급 난이도로 상향 조정) | 2차 테스트 진행 중 |
| 9 | 문제 풀이 완료 | 4번 문제에서 어려움을 느낌 | 테스트 진행 중 |
| 10 | "제출" 버튼 클릭 | 2차 응답 저장 + 자동 채점 (이번엔 78점) + 최종 평가 | 테스트 완료 |
| 11 | 최종 결과 페이지 노출 | **결과 요약:** 등급 "중상급" (이전 "중급"에서 상향), 총점 80/100, 이전 대비 +8점 향상, 순위 "상위 22%" (이전 28%에서 상향) | 결과 확인 |
| 12 | 결과 상세 확인 | 이전 응답과의 비교: 개선된 분야 (LLM: 80% → 85%), 여전히 약한 분야 (Deep Learning: 70%) | 결과 분석 |
| 13 | "학습 로드맵 보기" 클릭 (향후 시나리오 2.0의 학습 코디네이터 연계) | 추천 학습 자료 노출 (Deep Learning 관련 강화 학습 아이템) | 다음 단계 안내 |

**예상 결과**

- ✅ 기존 사용자의 프로필 정보 업데이트 (관심분야 추가)
- ✅ 새로운 test_sessions 레코드 생성 (기존 세션과 분리)
- ✅ 적응형 난이도 조정: 1차 점수 기반 2차 난이도 상향
- ✅ 최종 등급 변동: "intermediate" → "intermediate-advanced"
- ✅ 순위 변동 반영: 상위 28% → 상위 22%
- ✅ 이전 응시 기록과 비교 데이터 제시

**검증 포인트**

- 기존 프로필 정보가 정확히 로드되는가?
- 이전 응시 기록이 새 응시와 명확히 분리되는가?
- 적응형 난이도 조정이 이전 점수를 정확히 반영하는가?
- 등급 변동 로직이 정확한가?
- 순위 재계산이 정상 작동하는가?
- 사용자의 개선/퇴보 여부를 정확히 분석하는가?

---

### Scenario 1-3: 다양한 배경의 사용자 - 경력 많은 임직원의 테스트 (고급 단계 진행)

**사용자 프로필**

- 이름: 박준호 (입사 8년 차, 팀 리더)
- 닉네임: "준호"
- 현재 상태: 신규 가입자 (첫 테스트)
- 배경: 시니어 엔지니어, Agentic AI 연구 경험 보유

**상황**

- 가입 후 첫 테스트 응시
- 높은 경력으로 인해 높은 수준의 문제가 출제될 것으로 예상

**흐름**

| 단계 | 액션 | 시스템 응답 | 사용자 상태 |
|------|------|----------|----------|
| 1 | 테스트 시작 → 정보 입력 페이지 | 정보 입력 폼 노출 | 테스트 사전 정보 입력 중 |
| 2 | 자신이 생각하는 수준: "상급" | 선택 | 수준 선택 |
| 3 | 경력(연차): "8년" | 입력 | 경력 입력 |
| 4 | 직군: "시니어 엔지니어 / 팀 리더" | 선택 | 직군 선택 |
| 5 | 담당 업무: "Agentic AI 시스템 아키텍처, LangGraph/LangChain 기반 에이전트 설계" | 입력 | 담당 업무 입력 |
| 6 | 관심분야: ["LLM", "RAG", "Agent Architecture", "Prompt Engineering"] | 체크박스 다중 선택 | 관심분야 선택 |
| 7 | "다음" 클릭 | 백엔드: 프로필 저장 + 1차 테스트 문제 생성 (LLM 기반, "상급" 난이도 + "Agent Architecture" 분야 강화) | 1차 테스트 시작 준비 |
| 8 | 1차 테스트 페이지 로드 | 5개 문제 노출 (상급 난이도: 실무 시나리오 기반, 예: "LangGraph와 LangChain의 Agent 메커니즘 차이점 설명", "Multi-turn 대화에서 Context Window 관리 전략") | 1차 테스트 진행 중 |
| 9 | 문제 풀이 완료 (약 12분) | 높은 전문성으로 인해 90점 획득 | 1차 완료 |
| 10 | 2차 테스트 생성 | 1차 점수 90점이 매우 높으므로 → 2차도 상급 유지 또는 "초상급" 난이도 활성화 | 2차 테스트 시작 준비 |
| 11 | 2차 테스트 페이지 로드 | 5개 문제 노출 (초상급: 최신 연구 논문 기반, 예: "Mixture of Agents 아키텍처의 장단점", "Agent와 Vector DB 통합 시 Retrieval Strategy 최적화") | 2차 테스트 진행 중 |
| 12 | 문제 풀이 진행 (약 16분) | 매우 심화된 질문이라 일부 질문에서 시간 소요 | 테스트 진행 중 |
| 13 | "제출" 클릭 | 2차 채점: 85점 획득 (매우 높은 수준이나 일부 구체적 최신 논문 추적은 한계) | 테스트 완료 |
| 14 | 최종 결과 페이지 | **결과 요약:** 등급 "엘리트 (상급+)", 종합 점수 87/100, 분야별 (LLM: 92%, RAG: 88%, Agent Architecture: 85%), 순위 "상위 5%" (전사 506명 중 25명), 특수 배지 "Agent Specialist" 부여 | 결과 확인 |
| 15 | 결과 상세 | 풀이 내용 + 근거 자료 (참고 논문 링크, 모범 답안) + 등급 해설 ("엘리트: 최고 상위 5% 수준, 팀 내 기술 리더로서의 역량 입증") | 결과 분석 |
| 16 | 추가 옵션 | 특수 기능 노출: "마스터 클래스 강사 추천 프로그램" 링크 또는 "커뮤니티 기여자 등록" 옵션 | 향후 역할 제시 |

**예상 결과**

- ✅ 사용자 프로필 저장 (경력 8년, 상급 + Agentic AI 전문성 기록)
- ✅ 1차 테스트: 상급 난이도 문제로 90점 획득
- ✅ 2차 테스트: 적응형 난이도 "초상급"으로 조정
- ✅ 최종 등급: "엘리트" (기존 5단계보다 상위 등급 생성)
- ✅ 상위 5% 순위 반영
- ✅ 특수 배지/역할 제시 (향후 학습 코디네이터 시나리오 연계 가능)

**검증 포인트**

- 고경력 사용자의 높은 점수를 정확히 처리하는가?
- 적응형 난이도 조정이 상급 이상에서도 정상 작동하는가?
- 특수 등급(엘리트) 생성 로직이 정상 작동하는가?
- 순위 계산 시 상위 소수 순위가 정확한가?
- 특수 배지/역할 부여 로직이 정상 작동하는가?
- 마스터 클래스 강사 추천 등 향후 커리어 경로 제시가 의도대로 작동하는가?

---

## 시나리오 1-4: 재미 모드 (카테고리 선택형 퀴즈)

**목적**: 가벼운 참여 유도 — 마케팅, 반도체, 센서, RTL 등 **특화 카테고리**로 짧은 퀴즈를 진행하여 학습 동기를 높인다.

**관련 에이전트**:

- **Fun-Gen-Agent**: 3~5문항의 라이트 퀴즈 생성 (선택된 카테고리, 단기 형식)
- **Scoring-Agent**: 즉시 채점
- **Badge-Service**: 참여 배지/포인트 발급

**주요 흐름**:

| 단계 | 액션 | 시스템 응답 | 상태 |
|------|------|----------|------|
| 1 | 대시보드에서 "재미 모드" 클릭 | 카테고리 선택 페이지 노출 (마케팅/반도체/센서/RTL/기타) | 모드 진입 |
| 2 | 카테고리 선택: "반도체" | 선택 완료 | 카테고리 선택됨 |
| 3 | "시작" 버튼 클릭 | Fun-Gen-Agent가 반도체 관련 3~5문항 생성 (객관식/OX) | 퀴즈 시작 |
| 4 | 문제 풀이 (약 3~5분) | 사용자가 빠르게 답변 입력 | 풀이 진행 중 |
| 5 | "제출" 버튼 클릭 | 즉시 채점 + 점수 표시 | 채점 완료 |
| 6 | 결과 페이지 노출 | 점수, 짧은 해설, 참고 링크 제시 | 결과 확인 |
| 7 | Badge-Service 발동 | 참여 배지/포인트 지급 (예: "센서 마스터 배지 +50포인트") | 보상 지급 |
| 8 | "결과 공유" 클릭 | 사내 피드 공유 버튼 제공 (카카오톡/사내SNS 등) | 공유 옵션 |

**예상 결과**:

- ✅ 재미 모드 카테고리별 문제 생성 및 채점
- ✅ 참여 배지/포인트 발급
- ✅ 사내 피드 공유 가능
- ✅ 가벼운 학습 참여 동기 부여

**검증 포인트**:

- 카테고리별 문제 생성 알고리즘이 정상 작동하는가?
- 배지/포인트 발급 로직이 정확한가?
- 공유 기능이 정상 작동하는가?

---

## 시나리오 1-5: 학습 일정 예고 (MVP 2.0 프리뷰)

**목적**: 시나리오 1 결과 완료 후, **학습 코디네이터(MVP 2.0)** 기능을 프리뷰로 "초안 학습 일정"을 안내하여 다음 단계로 자연스럽게 유도한다.

**관련 에이전트**:

- **Plan-Preview-Agent**: 사용자 프로필/약점 기반 맞춤 2~4주 학습 계획 초안 생성
- **Nudge-Service**: 관심 표현 시 대기리스트 등록 및 향후 안내

**주요 흐름**:

| 단계 | 액션 | 시스템 응답 | 상태 |
|------|------|----------|------|
| 1 | 레벨 테스트 결과 화면 | 결과 요약 표시 (등급, 점수, 순위) | 결과 확인 |
| 2 | 결과 화면 하단 스크롤 | **"학습 일정 초안 보기(MVP 2.0 프리뷰)" CTA 버튼 노출** | CTA 노출 |
| 3 | "학습 일정 보기" 클릭 | Plan-Preview-Agent가 **2~4주 맞춤 학습 초안** 생성 | 일정 생성 중 |
| 4 | 초안 일정 표시 | 주당 학습량, 카테고리별 추천(사내/사외/영상/블로그), 예상 시간 표시 | 초안 확인 |
| 5 | "관심 있음" 클릭 | 사용자가 대기리스트 등록 요청 | 등록 진행 |
| 6 | 확인 모달 | "MVP 2.0 학습 코디네이터 오픈 시 자동 알림" 안내 + 이메일 구독 옵션 | 등록 완료 |
| 7 | (선택) 프리뷰 비노출 옵션 | "다시 보지 않기" 체크박스 제공 | 설정 저장 |

**예상 결과**:

- ✅ 맞춤 학습 일정 초안 제시
- ✅ 사용자 대기리스트 등록
- ✅ MVP 2.0 기대감 형성
- ✅ 다음 단계로의 자연스러운 이동

**검증 포인트**:

- Plan-Preview-Agent가 사용자 약점을 정확히 반영한 초안을 생성하는가?
- 주당 학습량이 사용자에게 과부하가 아닌가?
- 대기리스트 등록이 정상 작동하는가?
- 이메일 알림 기능이 정상 작동하는가?

---

## 통합 검증 시나리오

### 기술 요구사항 검증 (모든 시나리오 공통)

| 기술 항목 | 검증 내용 | 관련 시나리오 |
|----------|---------|------------|
| **Authentication & Authorization** | AD 로그인, JWT 토큰 관리, 세션 보안 | 0-1, 0-2, 0-3 |
| **Database Transactions** | 사용자 정보 저장, 닉네임 중복 검증 (UNIQUE 제약), 동시성 제어 | 0-1, 0-2, 0-3 |
| **LLM-based Problem Generation** | 동적 문제 생성, 난이도별 프롬프트 엔지니어링 | 1-1, 1-2, 1-3 |
| **Adaptive Testing Algorithm** | 1차 점수 기반 2차 난이도 조정, 등급 산출 | 1-1, 1-2, 1-3 |
| **Auto-scoring Logic** | 객관식/주관식 채점, LLM 기반 주관식 평가 | 1-1, 1-2, 1-3 |
| **Ranking & Statistics** | 사용자 순위 계산, 상위 % 계산, 분포 분석 | 1-1, 1-2, 1-3 |
| **Real-time Data Persistence** | 테스트 진행 중 응답 임시 저장 | 1-1, 1-2 |
| **Session Timeout Handling** | 20분 제한 시 처리 로직 | 1-1, 1-2, 1-3 |
| **Error Handling & Validation** | 닉네임 중복, 필드 검증, 네트워크 오류 | 0-1, 0-2, 0-3, 1-1, 1-2, 1-3 |

---

# AI Agent 아키텍처

시스템의 모든 시나리오는 **Multi-AI-Agent 구조**로 설계되어 있으며, 각 에이전트는 특정 역할을 수행합니다:

## 핵심 에이전트 목록

| 에이전트 | 역할 | 담당 시나리오 | 주요 기능 |
|---------|------|------------|---------|
| **Auth-Service** | Samsung AD 인증 및 JWT 토큰 관리 | 시나리오 0 | SSO 로그인, 세션 관리, 토큰 갱신 |
| **Profile-Service** | 사용자 프로필 관리 | 시나리오 0, 1 | 닉네임 검증, 중복 확인, 프로필 저장 |
| **Item-Gen-Agent** | 동적 문제 생성 (LLM 기반, MVP 2.0부터 RAG 통합) | 시나리오 1, 1-4 | 사용자 정보 기반 맞춤 문제 생성, 난이도 조정 |
| **Scoring-Agent** | 자동 채점 및 점수 계산 | 시나리오 1, 1-4 | 객관식 채점, LLM 기반 주관식 평가 |
| **Explain-Agent** | 풀이 해설 및 참고자료 생성 | 시나리오 1, 1-4 | 각 문제의 정답/해설, 학습 링크 제시 |
| **Rank-Service** | 순위 계산 및 통계 | 시나리오 1 | 사용자 순위, 백분위 계산, 등급 산출 |
| **History-Service** | 이전 응시 이력 조회 | 시나리오 1-2 | 응시 이력 로드, 비교 데이터 준비 |
| **Compare-Service** | 결과 비교 분석 | 시나리오 1-2 | 등급/점수 추이, 개선/퇴보 분석 |
| **Fun-Gen-Agent** | 재미 모드 문제 생성 | 시나리오 1-4 | 카테고리별 가벼운 퀴즈 생성 |
| **Badge-Service** | 배지/포인트 발급 | 시나리오 1-4 | 참여 보상, 특수 배지 관리 |
| **Plan-Preview-Agent** | 학습 계획 초안 생성 | 시나리오 1-5 | 사용자 약점 기반 2~4주 학습 계획 수립 |
| **Nudge-Service** | 대기리스트 및 알림 | 시나리오 1-5 | 대기리스트 등록, 이메일/푸시 알림 |
| **Item-Registry-Agent** | 학습 아이템 등록 | 시나리오 2 (MVP 2.0) | 아이템 검증, 메타데이터 추출 |
| **Item-Review-Agent** | 학습 아이템 평가 | 시나리오 3 (MVP 2.0) | 별점/후기 저장, 비용 정보 관리 |
| **Item-Search-Agent** | 학습 아이템 검색 | 시나리오 4 (MVP 2.0) | 키워드 검색, 필터/정렬, 추천 |

## 에이전트 간 상호작용 흐름

```text
시나리오 1 (레벨 테스트) 예시:

User Input
    ↓
Profile-Service (사용자 정보 저장)
    ↓
Item-Gen-Agent (1차 문제 생성)
    ↓
User Solving
    ↓
Scoring-Agent (자동 채점) → Explain-Agent (해설 생성)
    ↓
Rank-Service (점수 평가) → Item-Gen-Agent (2차 난이도 조정)
    ↓
User Solving (2차)
    ↓
Scoring-Agent + Rank-Service (최종 평가 + 순위 계산)
    ↓
Compare-Service (이전 이력과 비교, 적용 가능 시)
    ↓
Plan-Preview-Agent (학습 계획 초안 생성)
    ↓
Result Display + Nudge-Service (대기리스트 등록)
```

---

# MVP 2.0 시나리오

---

## 시나리오 1-6: RAG 기반 동적 문제 생성 (MVP 2.0 강화)

**목적**: MVP 2.0에서는 Item-Gen-Agent가 **RAG(Retrieval-Augmented Generation)** 기능을 통합하여, 문제 은행뿐만 아니라 사내/사외 지식 베이스에서 최신 정보를 검색하여 문제를 생성합니다.

**MVP 1.0 vs MVP 2.0 비교**:

| 항목 | MVP 1.0 | MVP 2.0 |
|------|---------|---------|
| **문제 생성 방식** | LLM이 학습된 지식만으로 문제 생성 | LLM + RAG: 실시간 정보 검색 후 문제 생성 |
| **정보 소스** | 고정된 프롬프트 + 모델 가중치 | 동적 벡터 DB + 외부 지식 베이스 |
| **최신성** | 모델 학습 시점 기준 | 실시간 업데이트 가능 |
| **카테고리 확장** | 사전 정의된 카테고리만 지원 | 새로운 카테고리 동적 추가 가능 |
| **RAG 소스 추적** | 해당 없음 | 문헌명, URL, 버전, 타임스탬프 저장 |

**MVP 2.0 주요 기능**:

1. **RAG 통합**: Item-Gen-Agent가 벡터 DB에서 관련 문헌/자료를 검색
2. **소스 추적**: 각 문제의 출처(문헌명, URL, 버전)를 메타데이터로 저장
3. **품질 향상**: 최신 연구, 사내 가이드 등 신뢰할 수 있는 소스 기반 문제 생성
4. **다양성 확대**: 제약 없이 새로운 주제/카테고리 추가 가능

**검증 포인트 (MVP 2.0)**:

- RAG 벡터 DB 검색이 정상 작동하는가?
- 검색된 정보에서 관련도 높은 자료를 우선 선택하는가?
- RAG 소스 메타가 정확하고 추적 가능한가?
- 부정확/오래된 정보를 자동으로 필터링하는가?
- 소스 기반 문제의 정확도가 LLM 단독 생성보다 높은가?

---

## 시나리오 2: 학습 아이템 등록

### BDD: User Story & Acceptance Criteria

- **As a** 허용된 사용자 또는 학습 관리 AI 에이전트
- **I want to** 시스템에 유용한 AI 학습 자료(사내외 동영상, 블로그, 문서 등)를 정해진 양식으로 등록한다.
- **So that** 조직의 AI 학습 콘텐츠 풀을 풍부하게 만들어 동료들과 공유한다.

#### ✅ Acceptance Criteria

1. **권한 관리**: 허용된 사용자만 학습 아이템 등록 메뉴에 접근 가능해야 한다 (관리자 개입 최소화).
2. **필수 메타데이터**: 다음 정보를 입력해야 한다:
   - 제목, URL, 설명
   - 시리즈명 (예: "LangChain 101", "RAG Deep Dive")
   - 카테고리 (LLM, RAG, Agent Architecture, Prompt Engineering, Deep Learning 등)
   - 레벨 (초급, 중급, 상급)
   - 예상 학습 시간
   - 타입 (사내/사외, 동영상/블로그/문서)

3. **AI 지원**: Item-Registry-Agent가 입력된 URL/문서를 분석하여 메타데이터를 **자동 제안**할 수 있어야 한다.
4. **검증**: 중복 URL 확인, 유효한 링크 검증을 수행해야 한다.
5. **저장 및 상태**: 등록된 아이템은 DB에 저장되고, "검수 대기" 또는 "승인 완료" 상태로 관리되어야 한다.

**예상 결과**:

- ✅ 학습 아이템 DB 저장
- ✅ 메타데이터 정확성 검증
- ✅ 중복 방지

**검증 포인트**:

- 권한 관리 로직이 정상 작동하는가?
- 자동 메타데이터 제안 알고리즘이 정확한가?
- URL 유효성 검증이 정상 작동하는가?

---

## 시나리오 3: 학습 아이템 평가

### BDD: User Story & Acceptance Criteria

- **As a** 학습 아이템을 본 또는 완료한 사용자
- **I want to** 내가 본 학습 아이템에 대해 별점, 한 줄 후기, (필요시) 실제 비용 정보를 남긴다.
- **So that** 학습 아이템의 품질을 평가하고, 이 정보를 다른 사용자들과 공유하여 집단 지성을 활용한다.

#### ✅ Acceptance Criteria

1. **별점 평가**: 사용자는 학습 아이템 상세 페이지에서 1~5점의 별점을 매길 수 있어야 한다.
2. **텍스트 후기**: 사용자는 해당 아이템에 대한 자유로운 텍스트 후기를 작성할 수 있어야 한다 (예: "개념 설명이 명확하고 실습 코드가 유용함").
3. **비용 정보 (선택)**: 유료 강의의 경우, 허용된 사용자는 실제 비용을 입력/수정할 수 있어야 한다.
4. **저장 및 공개**: 별점, 후기, 비용 정보는 DB에 저장되고, 해당 아이템의 상세 페이지에 **평균 별점**으로 노출되어야 한다.
5. **익명성 (선택)**: 사용자가 익명으로 후기를 남기는 옵션을 제공할 수 있다.

**예상 결과**:

- ✅ 사용자 평가 저장
- ✅ 평균 별점 계산 및 노출
- ✅ 후기 검색 및 필터링

**검증 포인트**:

- 별점 및 후기 저장이 정상 작동하는가?
- 평균 별점 계산이 정확한가?
- 비용 정보 입력 권한이 정상 작동하는가?

---

## 시나리오 4: 학습 아이템 검색

### BDD: User Story & Acceptance Criteria

- **As a** 특정 AI 지식이 필요한 사용자
- **I want to** 키워드 검색, 카테고리/레벨/타입별 필터, 그리고 정렬(인기순/최신순) 기능을 이용해 원하는 학습 아이템을 찾는다.
- **So that** 나의 필요와 수준에 맞는 학습 자료를 시스템 내에서 빠르고 효율적으로 발견한다.

#### ✅ Acceptance Criteria

1. **키워드 검색**: 사용자는 제목, 설명, 태그 등을 포함한 **통합 검색**을 수행할 수 있어야 한다.
2. **필터 기능**: 다음 필터를 조합하여 검색 결과를 좁힐 수 있어야 한다:
   - 카테고리 (LLM, RAG, Agent Architecture 등)
   - 레벨 (초급, 중급, 상급)
   - 타입 (사내/사외, 동영상/블로그/문서)
   - 시리즈

3. **정렬 기능**: 검색 결과를 다음 기준으로 재정렬할 수 있어야 한다:
   - 관련도 (기본)
   - 인기순 (평균 별점)
   - 최신순 (등록일)

4. **상세 정보**: 검색 결과 목록에서 아이템을 선택하면, 메타데이터, 평균 별점, 후기 목록을 조회할 수 있어야 한다.

5. **추천 기능 (선택)**: 사용자의 레벨과 관심분야 기반 **개인화된 추천 아이템**을 별도 섹션에 표시할 수 있다.

**예상 결과**:

- ✅ 검색 및 필터링 정상 작동
- ✅ 정렬 기능 정상 작동
- ✅ 개인화 추천 제시 (선택)

**검증 포인트**:

- 검색 알고리즘이 정확하고 빠른가?
- 필터 조합이 정상 작동하는가?
- 정렬 우선순위가 의도대로 작동하는가?
- 개인화 추천이 사용자의 레벨을 정확히 반영하는가?

---

# 공통 원칙 및 설계 철학

## 1. 관리자 개입 최소화

- 모든 시나리오는 **에이전트 중심 자동화**로 설계되어 있습니다.
- 문제 생성, 채점, 해설, 추천, 랭킹 등이 모두 AI 에이전트에 의해 자동 처리됩니다.
- 관리자는 최소한의 개입(예: 권한 관리, 부적절 콘텐츠 검수)만 수행합니다.

## 2. Multi-AI-Agent 아키텍처

- 각 기능 영역마다 전담 에이전트가 배치되어 있습니다.
- 에이전트 간 느슨한 결합(Loose Coupling)으로 독립적 개발 및 테스트가 가능합니다.
- 확장성: 새로운 에이전트 추가 시 기존 시스템에 영향 최소화.

## 3. 사용자 경험 흐름

```text
쉬운 경험 → 테스트 → 결과 해설 → 다음 행동 유도
   (가입)   (적응형)  (상세분석)  (재응시/학습)
```

## 4. MVP 범위 명확화

**MVP 1.0** (핵심 기능):

- 사용자 가입 & 인증
- 2단계 적응형 레벨 테스트
- 자동 채점 & 랭킹
- 재미 모드 (보조 기능)
- 학습 일정 예고 (다음 단계 유도)

**MVP 2.0** (학습 코디네이터):

- 학습 아이템 관리 (등록/평가/검색)
- 개인화된 학습 계획 수립
- 커뮤니티 기능

## 5. 에러 처리 & 복원력

- **진행상태 자동 저장**: 테스트 중단 시 이어서 진행 가능
- **네트워크 오류 처리**: 재시도 로직 및 사용자 안내
- **데이터 검증**: 모든 입력값 유효성 검사
- **세션 타임아웃**: 20분 제한 초과 시 저장된 상태에서 재개

## 6. 동시성 제어

- **닉네임 중복 검증**: UNIQUE 제약 + DB 트랜잭션
- **순위 계산**: 동일 점수 처리 규칙 명확화
- **프로필 업데이트**: 낙관적 잠금(Optimistic Locking) 또는 비관적 잠금 검토

---

## 데이터 흐름 및 API 정의 (추후 상세화)

### 시나리오 0 관련 API

```http
POST /api/v1/auth/ad-login
  → 응답: JWT token, user_id

POST /api/v1/users/register
  요청: {nickname: string}
  → 응답: user_id, status='registered'

POST /api/v1/users/check-nickname
  요청: {nickname: string}
  → 응답: {available: boolean}

PUT /api/v1/users/{user_id}/nickname
  요청: {nickname: string}
  → 응답: {success: boolean}
```

### 시나리오 1 관련 API

```http
POST /api/v1/users/{user_id}/profile
  요청: {level, career, department, tasks, interests}
  → 응답: profile_id

POST /api/v1/tests/generate-questions
  요청: {user_id, round: 1|2, previous_score?: number}
  → 응답: {session_id, questions: [{id, type, content, options}]}

POST /api/v1/tests/{session_id}/submit-answer
  요청: {question_id, answer}
  → 응답: {saved: boolean}

POST /api/v1/tests/{session_id}/submit
  → 응답: {score, grade, next_round_questions}

GET /api/v1/tests/{user_id}/results
  → 응답: {grade, score, rank, rank_percentage, breakdown_by_category}
```

---

## 추후 고려사항 (MVP 2.0 연계)

1. **학습 경로 추천**: 1차 테스트 결과 기반으로 개인화된 학습 로드맵 자동 생성 (시나리오 5)
2. **레벨별 커뮤니티**: 등급별 그룹화 및 peer learning 플랫폼
3. **재응시 권장 시기**: 데이터 분석 기반 재응시 최적 타이밍 알림
4. **마스터 클래스**: 엘리트 등급 사용자를 강사로 등록하고 커뮤니티 강의 제공
5. **분석 대시보드**: 관리자용 응시 현황, 등급 분포, 난이도 조정 효율성 분석
